"""
Azusa Radar â€” Streamlit å‰ç«¯ Dashboard
é€é Backend API é¡¯ç¤ºè¿½è¹¤è‚¡ç¥¨ã€æŠ€è¡“æŒ‡æ¨™èˆ‡è§€é»ç‰ˆæ§ã€‚
"""

import json

import pandas as pd
import requests
import streamlit as st
from streamlit_sortables import sort_items

from config import (
    API_DELETE_TIMEOUT,
    API_DIVIDEND_TIMEOUT,
    API_EARNINGS_TIMEOUT,
    API_GET_TIMEOUT,
    API_PATCH_TIMEOUT,
    API_POST_TIMEOUT,
    API_PUT_TIMEOUT,
    API_SIGNALS_TIMEOUT,
    BACKEND_URL,
    BIAS_OVERHEATED_UI,
    BIAS_OVERSOLD_UI,
    CACHE_TTL_ALERTS,
    CACHE_TTL_DIVIDEND,
    CACHE_TTL_EARNINGS,
    CACHE_TTL_MOAT,
    CACHE_TTL_REMOVED,
    CACHE_TTL_SCAN_HISTORY,
    CACHE_TTL_SIGNALS,
    CACHE_TTL_STOCKS,
    CACHE_TTL_THESIS,
    CATEGORY_LABELS,
    CATEGORY_OPTIONS,
    DEFAULT_ALERT_THRESHOLD,
    DEFAULT_TAG_OPTIONS,
    EARNINGS_BADGE_DAYS_THRESHOLD,
    EXPORT_FILENAME,
    MARGIN_BAD_CHANGE_THRESHOLD,
    PRICE_WEAK_BIAS_THRESHOLD,
    SCAN_HISTORY_CARD_LIMIT,
    WHALEWISDOM_STOCK_URL,
)

# ---------------------------------------------------------------------------
# é é¢è¨­å®š
# ---------------------------------------------------------------------------

st.set_page_config(
    page_title="æŠ•è³‡é›·é” Azusa Radar",
    page_icon="ğŸ“¡",
    layout="wide",
)

st.title("ğŸ“¡ æŠ•è³‡é›·é” Azusa Radar")
st.caption("V2.0 â€” ä¸‰å±¤æ¼æ–— + ç±Œç¢¼é¢è¨Šè™Ÿ")

with st.expander("ğŸ“– æŠ•è³‡é›·é”ï¼šä½¿ç”¨èªªæ˜æ›¸ (SOP)", expanded=False):
    st.markdown("""
### ç³»çµ±ç¸½è¦½

æœ¬ç³»çµ±å°‡è‚¡ç¥¨åˆ†ç‚º**å››å¤§é¡åˆ¥**ï¼Œå„è‡ªå°æ‡‰ä¸åŒçš„è¿½è¹¤é‚è¼¯ï¼š

| åˆ†é¡ | èªªæ˜ |
|------|------|
| ğŸŒŠ **é¢¨å‘çƒ (Trend Setter)** | å¤§ç›¤ ETFã€å·¨é ­ï¼Œè§€å¯Ÿè³‡é‡‘æµå‘èˆ‡ Capex |
| ğŸ° **è­·åŸæ²³ (Moat)** | ä¾›æ‡‰éˆä¸­ä¸å¯æ›¿ä»£çš„è³£éŸå­å…¬å¸ |
| ğŸš€ **æˆé•·å¤¢æƒ³ (Growth)** | é«˜æ³¢å‹•ã€å…·æƒ³åƒç©ºé–“çš„æˆé•·è‚¡ |
| ğŸ§º **ETF** | æŒ‡æ•¸å‹åŸºé‡‘ï¼Œè¢«å‹•è¿½è¹¤å¸‚å ´æˆ–ç‰¹å®šä¸»é¡Œ |

---

### æ“ä½œæµç¨‹

---

#### 1. æŠ¬é ­çœ‹å¤©æ°£ â€” é»æ“Šã€ŒğŸš€ åŸ·è¡Œæƒæã€

é»æ“Šå·¦å´é¢æ¿çš„æƒææŒ‰éˆ•ï¼Œç³»çµ±æœƒåœ¨**èƒŒæ™¯**åŸ·è¡Œ **V2 ä¸‰å±¤æ¼æ–—åˆ†æ**ï¼ˆä¸¦è¡Œæƒæ 4 è‚¡ï¼Œç´„ 30 ç§’å®Œæˆï¼‰ã€‚ç³»çµ±ä¹Ÿæœƒæ¯ 30 åˆ†é˜è‡ªå‹•æƒæä¸€æ¬¡ã€‚

é¦–å…ˆè§€å¯Ÿ **Layer 1 å¸‚å ´æƒ…ç·’**ï¼š

| ç‡ˆè™Ÿ | æ„ç¾© | å»ºè­° |
|------|------|------|
| ğŸŸ¢ **POSITIVEï¼ˆæ™´å¤©ï¼‰** | é¢¨å‘çƒè‚¡ç¥¨ç©©å¥ï¼Œè³‡é‡‘é¢æ­£å¸¸ | é©åˆå°‹æ‰¾å€‹è‚¡è²·é» |
| ğŸ”´ **CAUTIONï¼ˆé›¨å¤©ï¼‰** | é¢¨å‘çƒè½‰å¼±ï¼ˆ>50% è·Œç ´ 60MAï¼‰ï¼Œå¸‚å ´é¢¨éšªå‡é«˜ | å»ºè­°ç¸®æ‰‹è§€æœ›æˆ–ç©ºæ‰‹ |

æƒæçµæœé€é **Telegram å·®ç•°é€šçŸ¥**æ¨æ’­ â€” åªæœ‰è¨Šè™Ÿç™¼ç”Ÿ**è®ŠåŒ–**æ™‚æ‰æœƒæ”¶åˆ°é€šçŸ¥ï¼Œä¸æœƒé‡è¤‡æ¨æ’­ç›¸åŒè¨Šè™Ÿã€‚

> ğŸ’¡ é€™ä¸€æ­¥æ±ºå®šä½ çš„ã€Œå€‰ä½æ°´ä½ã€ï¼Œå¤©æ°£ä¸å¥½å°±ä¸è¦å‡ºæµ·ã€‚

---

#### 2. æª¢æŸ¥è­·åŸæ²³ â€” å±•é–‹ã€ŒğŸ° è­·åŸæ²³æª¢æ¸¬ã€

æ¯å¼µè‚¡ç¥¨å¡ç‰‡éƒ½æœ‰ã€ŒğŸ° è­·åŸæ²³æª¢æ¸¬ã€å±•é–‹å€ï¼ŒåŒ…å«ï¼š
- **æ¯›åˆ©ç‡æŒ‡æ¨™**ï¼šæœ€æ–°æ¯›åˆ©ç‡ + YoY è®ŠåŒ–é‡ï¼ˆç™¾åˆ†é»ï¼‰
- **5 å­£èµ°å‹¢åœ–**ï¼šæŠ˜ç·šåœ–ç›´è§€å‘ˆç¾æ¯›åˆ©ç‡è¶¨å‹¢
- **äº”ç´šè‡ªå‹•è¨ºæ–·**ï¼š
  - ğŸ”´ **Thesis Broken** â€” æ¯›åˆ© YoY è¡°é€€è¶…é 2ppï¼Œè­·åŸæ²³å—æï¼Œå‹¿æ¥åˆ€
  - ğŸŸ¢ **éŒ¯æ®ºæ©Ÿæœƒ** â€” è‚¡åƒ¹å›æª”ï¼ˆä¹–é›¢ç‡ < -5%ï¼‰ä½†æ¯›åˆ©æˆé•·ï¼ŒåŸºæœ¬é¢å¼·å‹
  - ğŸŸ¢ **è­·åŸæ²³ç©©å›º** â€” æ¯›åˆ©ç‡ YoY æˆé•·ï¼ŒåŸºæœ¬é¢å¥åº·
  - ğŸŸ¡ **è‚¡åƒ¹åå¼±** â€” ä¹–é›¢ç‡åä½ä½†è­·åŸæ²³æ•¸æ“šæŒå¹³ï¼Œç•™æ„å¾ŒçºŒå­£å ±
  - âšª **è§€å¯Ÿä¸­** â€” è­·åŸæ²³æ•¸æ“šæŒå¹³ï¼ŒæŒçºŒè§€å¯Ÿ

> ğŸ’¡ è‚¡åƒ¹ä¸‹è·Œä¸å¯æ€•ï¼Œå¯æ€•çš„æ˜¯åŸºæœ¬é¢è·Ÿè‘—ä¸‹è·Œã€‚æ¯›åˆ©ç‡æ˜¯åˆ¤æ–·è­·åŸæ²³æœ€ç›´æ¥çš„æŒ‡æ¨™ã€‚

---

#### 3. åˆ¤æ–·ç‡ˆè™Ÿ â€” æŸ¥çœ‹æƒææ­·å²

æƒæå®Œæˆå¾Œï¼Œç³»çµ±å°æ¯æª”è‚¡ç¥¨ç”¢ç”Ÿæ±ºç­–è¨Šè™Ÿã€‚å±•é–‹ã€ŒğŸ“ˆ æƒææ­·å²ã€å¯æŸ¥çœ‹æœ€è¿‘ 10 æ¬¡æƒæçµæœï¼Œä»¥åŠ**é€£çºŒç•°å¸¸æ¬¡æ•¸**æç¤ºï¼š

| ç‡ˆè™Ÿ | è§¸ç™¼æ¢ä»¶ | æ“ä½œå»ºè­° |
|------|----------|----------|
| ğŸŸ¢ **CONTRARIAN_BUY** | RSI < 35 + å¸‚å ´æƒ…ç·’æ­£é¢ + è­·åŸæ²³ç©©å›º | è…³å°–è©¦æ°´æº«ï¼Œåˆ†æ‰¹ä½ˆå±€ |
| ğŸŸ¡ **OVERHEATED** | ä¹–é›¢ç‡ > 20% | éç†±è¨Šè™Ÿï¼Œè«‹å‹¿è¿½é«˜ |
| ğŸ”´ **THESIS_BROKEN** | æ¯›åˆ©ç‡ YoY è¡°é€€è¶…é 2 å€‹ç™¾åˆ†é» | åŸºæœ¬é¢è½‰å·®ï¼Œå»ºè­°åœæå‡ºå ´ |
| âšª **NORMAL** | ç„¡ç•°å¸¸ | æŒçºŒè§€å¯Ÿ |

> ğŸ’¡ ã€Œä¸è¦è·Ÿè‚¡ç¥¨è«‡æˆ€æ„›ã€â€” ç•¶ Thesis Broken å‡ºç¾æ™‚ï¼Œæœæ–·åŸ·è¡Œåœæã€‚

---

#### 4. è¨­å®šåƒ¹æ ¼è­¦å ± â€” å±•é–‹ã€ŒğŸ”” åƒ¹æ ¼è­¦å ±ã€

æ¯å¼µè‚¡ç¥¨å¡ç‰‡çš„ã€ŒğŸ”” åƒ¹æ ¼è­¦å ±ã€å±•é–‹å€å¯ä»¥ï¼š
- **å»ºç«‹è‡ªè¨‚è­¦å ±**ï¼šé¸æ“‡æŒ‡æ¨™ï¼ˆRSI / åƒ¹æ ¼ / ä¹–é›¢ç‡ï¼‰ã€æ¢ä»¶ï¼ˆ< æˆ– >ï¼‰ã€é–€æª»å€¼
- **æª¢è¦–ç¾æœ‰è­¦å ±**ï¼šæŸ¥çœ‹æ‰€æœ‰å·²è¨­å®šçš„è­¦å ±åŠè§¸ç™¼ç´€éŒ„
- **åˆªé™¤è­¦å ±**ï¼šä¸å†éœ€è¦æ™‚ä¸€éµç§»é™¤

è§¸ç™¼æ™‚ç³»çµ±é€é **Telegram å³æ™‚é€šçŸ¥**ï¼Œæ¯å€‹è­¦å ±æœ‰ **4 å°æ™‚å†·å»æœŸ**é¿å…é‡è¤‡æ¨æ’­ã€‚

> ğŸ’¡ å–„ç”¨ RSI < 30 æˆ– Bias < -20% ç­‰æ¢ä»¶ï¼Œè®“ç³»çµ±å¹«ä½ ç›¯ç›¤ã€‚

---

#### 5. ç¢ºèªå¤§æˆ¶å‹•å‘ â€” å±•é–‹ã€ŒğŸ³ ç±Œç¢¼é¢ (13F)ã€

æ¯å¼µè‚¡ç¥¨å¡ç‰‡çš„ã€ŒğŸ³ ç±Œç¢¼é¢ (13F)ã€å±•é–‹å€æä¾›ï¼š
- **WhaleWisdom é€£çµ**ï¼šä¸€éµæŸ¥çœ‹å®Œæ•´ 13F æ©Ÿæ§‹æŒå€‰å ±å‘Š
- **å‰äº”å¤§æ©Ÿæ§‹æŒæœ‰è€…**ï¼šè‹¥è³‡æ–™å¯å–å¾—ï¼Œç›´æ¥é¡¯ç¤ºè¡¨æ ¼
- é‡é»è§€å¯Ÿï¼š
  - **New / Addï¼ˆæ–°é€² / åŠ ç¢¼ï¼‰** â†’ å¤§æˆ¶æ­£åœ¨ä½ˆå±€
  - **Reduce / Sold Outï¼ˆæ¸›ç¢¼ / æ¸…å€‰ï¼‰** â†’ å¤§æˆ¶æ­£åœ¨æ’¤é€€

> ğŸ’¡ è·Ÿå–®è¦è·Ÿã€Œæ–°å¢ã€è€Œéåº«å­˜ã€‚è§€å¯Ÿæ³¢å…‹å¤ã€æ©‹æ°´ã€æ–‡è—å¾©èˆˆç­‰æŒ‡æ¨™æ€§æ©Ÿæ§‹ã€‚

---

#### 6. æŸ¥çœ‹è²¡å ±æ—¥èˆ‡è‚¡æ¯

æ¯å¼µè‚¡ç¥¨å¡ç‰‡è‡ªå‹•é¡¯ç¤ºï¼š
- **ğŸ“… è²¡å ±æ—¥**ï¼šä¸‹æ¬¡è²¡å ±ç™¼å¸ƒæ—¥æœŸï¼Œ14 å¤©å…§é¡¯ç¤ºå€’æ•¸å¤©æ•¸
- **ğŸ’° æ®–åˆ©ç‡**ï¼ˆè­·åŸæ²³ / ETF é¡ï¼‰ï¼šç•¶å‰è‚¡æ¯æ®–åˆ©ç‡èˆ‡é™¤æ¯æ—¥

> ğŸ’¡ è²¡å ±å‰å¾Œæ˜¯è­·åŸæ²³è«–é»è¢«é©—è­‰çš„é—œéµæ™‚åˆ»ï¼Œæå‰åšå¥½æº–å‚™ã€‚

---

#### 7. è¨˜éŒ„è§€é» â€” å±•é–‹ã€ŒğŸ“ è§€é»ç‰ˆæ§ã€

æŠ•è³‡æ±ºç­–éœ€è¦ç•™ä¸‹ç´€éŒ„ï¼Œé¿å…äº‹å¾Œåå·®ï¼š
- å±•é–‹è‚¡ç¥¨å¡ç‰‡çš„ã€ŒğŸ“ è§€é»ç‰ˆæ§ã€ï¼Œå¯æŸ¥çœ‹**å®Œæ•´æ­·å²è§€é»**ï¼ˆå«ç‰ˆæœ¬è™Ÿèˆ‡æ—¥æœŸï¼‰
- æ¯æ¬¡æ›´æ–°è§€é»ï¼Œç³»çµ±è‡ªå‹•éå¢ç‰ˆæœ¬è™Ÿï¼ˆv1 â†’ v2 â†’ v3...ï¼‰
- å¯åŒæ™‚è¨­å®š**é ˜åŸŸæ¨™ç±¤**ï¼ˆAIã€Cloudã€SaaS...ï¼‰ï¼Œæ¨™ç±¤éš¨è§€é»ä¸€ä½µç‰ˆæ§å¿«ç…§

> ğŸ’¡ å®šæœŸå›é¡§è§€é»æ¼”é€²ï¼Œæ‰èƒ½ç™¼ç¾è‡ªå·±çš„ç›²é»èˆ‡é€²æ­¥ã€‚

---

#### 8. ç®¡ç†æ¸…å–® â€” æ’åºã€åˆ†é¡ã€åŒ¯å‡ºã€åŒ¯å…¥

- **â†•ï¸ æ‹–æ›³æ’åº**ï¼šæ¯å€‹åˆ†é é ‚éƒ¨çš„ã€Œâ†•ï¸ æ‹–æ›³æ’åºã€å¯èª¿æ•´è‚¡ç¥¨é¡¯ç¤ºé †ä½ï¼Œé»æ“Šã€ŒğŸ’¾ å„²å­˜æ’åºã€å¯«å…¥è³‡æ–™åº«
- **ğŸ”„ åˆ‡æ›åˆ†é¡**ï¼šè‚¡ç¥¨å¡ç‰‡å…§å¯ç›´æ¥åˆ‡æ›åˆ†é¡ï¼ˆä¾‹å¦‚å¾é¢¨å‘çƒç§»è‡³è­·åŸæ²³ï¼‰
- **ğŸ—‘ï¸ ç§»é™¤è¿½è¹¤**ï¼šç§»é™¤æ™‚éœ€å¡«å¯«åŸå› ï¼Œç§»é™¤å¾Œå¯åœ¨ã€ŒğŸ“¦ å·²ç§»é™¤ã€åˆ†é æŸ¥çœ‹æ­·å²
- **ğŸ”„ é‡æ–°å•Ÿç”¨**ï¼šåœ¨ã€ŒğŸ“¦ å·²ç§»é™¤ã€åˆ†é ï¼Œå¯å°‡å·²ç§»é™¤çš„è‚¡ç¥¨é‡æ–°å•Ÿç”¨åˆ°ä»»æ„åˆ†é¡
- **ğŸ“¥ åŒ¯å‡ºè§€å¯Ÿåå–®**ï¼šå·¦å´é¢æ¿å¯ä¸‹è¼‰ JSON æ ¼å¼çš„å®Œæ•´è§€å¯Ÿåå–®ï¼ˆå«è§€é»èˆ‡æ¨™ç±¤ï¼‰
- **ğŸ“¤ åŒ¯å…¥è§€å¯Ÿåå–®**ï¼šå·¦å´é¢æ¿å¯ä¸Šå‚³ JSON æª”æ¡ˆæ‰¹æ¬¡åŒ¯å…¥ï¼ˆæ”¯æ´ upsertï¼‰

---

#### 9. æ¯é€±æ‘˜è¦

æ¯é€±æ—¥ 18:00 UTCï¼Œç³»çµ±è‡ªå‹•ç™¼é€ **Telegram æŠ•è³‡çµ„åˆå¥åº·å ±å‘Š**ï¼ŒåŒ…å«ï¼š
- **å¥åº·åˆ†æ•¸**ï¼šæ­£å¸¸è‚¡ç¥¨ä½”æ¯”ï¼ˆä¾‹å¦‚ 85%ï¼‰
- **ç•°å¸¸è‚¡ç¥¨æ¸…å–®**ï¼šç›®å‰é NORMAL çš„è‚¡ç¥¨åŠå…¶è¨Šè™Ÿ
- **æœ¬é€±è¨Šè™Ÿè®ŠåŒ–**ï¼šéå» 7 å¤©å…§è¨Šè™Ÿè®Šå‹•çš„è‚¡ç¥¨èˆ‡è®Šå‹•æ¬¡æ•¸

> ğŸ’¡ æ¯é€±èŠ± 5 åˆ†é˜çœ‹æ‘˜è¦ï¼ŒæŒæ¡æ•´é«”æŠ•è³‡çµ„åˆç‹€æ…‹ã€‚
""")


# ---------------------------------------------------------------------------
# Helper Functions
# ---------------------------------------------------------------------------

def api_get(path: str) -> dict | list | None:
    """GET è«‹æ±‚ Backend APIã€‚"""
    try:
        resp = requests.get(f"{BACKEND_URL}{path}", timeout=API_GET_TIMEOUT)
        resp.raise_for_status()
        return resp.json()
    except requests.RequestException as e:
        st.error(f"âŒ API è«‹æ±‚å¤±æ•—ï¼š{e}")
        return None


def api_post(path: str, json_data: dict) -> dict | None:
    """POST è«‹æ±‚ Backend APIã€‚"""
    try:
        resp = requests.post(f"{BACKEND_URL}{path}", json=json_data, timeout=API_POST_TIMEOUT)
        resp.raise_for_status()
        return resp.json()
    except requests.RequestException as e:
        st.error(f"âŒ API è«‹æ±‚å¤±æ•—ï¼š{e}")
        return None


def api_patch(path: str, json_data: dict) -> dict | None:
    """PATCH è«‹æ±‚ Backend APIã€‚"""
    try:
        resp = requests.patch(f"{BACKEND_URL}{path}", json=json_data, timeout=API_PATCH_TIMEOUT)
        resp.raise_for_status()
        return resp.json()
    except requests.RequestException as e:
        st.error(f"âŒ API è«‹æ±‚å¤±æ•—ï¼š{e}")
        return None


def api_put(path: str, json_data: dict) -> dict | None:
    """PUT è«‹æ±‚ Backend APIã€‚"""
    try:
        resp = requests.put(f"{BACKEND_URL}{path}", json=json_data, timeout=API_PUT_TIMEOUT)
        resp.raise_for_status()
        return resp.json()
    except requests.RequestException as e:
        st.error(f"âŒ API è«‹æ±‚å¤±æ•—ï¼š{e}")
        return None


def api_delete(path: str) -> dict | None:
    """DELETE è«‹æ±‚ Backend APIã€‚"""
    try:
        resp = requests.delete(f"{BACKEND_URL}{path}", timeout=API_DELETE_TIMEOUT)
        resp.raise_for_status()
        return resp.json()
    except requests.RequestException as e:
        st.error(f"âŒ API è«‹æ±‚å¤±æ•—ï¼š{e}")
        return None


@st.cache_data(ttl=CACHE_TTL_STOCKS, show_spinner="è¼‰å…¥è‚¡ç¥¨è³‡æ–™ä¸­...")
def fetch_stocks() -> list | None:
    """å–å¾—æ‰€æœ‰è¿½è¹¤è‚¡ç¥¨ï¼ˆåƒ… DB è³‡æ–™ï¼‰ã€‚"""
    return api_get("/stocks")


@st.cache_data(ttl=CACHE_TTL_SIGNALS, show_spinner=False)
def fetch_signals(ticker: str) -> dict | None:
    """å–å¾—å–®ä¸€è‚¡ç¥¨çš„æŠ€è¡“è¨Šè™Ÿï¼ˆyfinanceï¼‰ã€‚"""
    try:
        resp = requests.get(f"{BACKEND_URL}/ticker/{ticker}/signals", timeout=API_SIGNALS_TIMEOUT)
        resp.raise_for_status()
        return resp.json()
    except requests.RequestException:
        return None


@st.cache_data(ttl=CACHE_TTL_REMOVED, show_spinner="è¼‰å…¥å·²ç§»é™¤è‚¡ç¥¨...")
def fetch_removed_stocks() -> list | None:
    """å–å¾—å·²ç§»é™¤è‚¡ç¥¨æ¸…å–®ã€‚"""
    return api_get("/stocks/removed")


@st.cache_data(ttl=CACHE_TTL_EARNINGS, show_spinner=False)
def fetch_earnings(ticker: str) -> dict | None:
    """å–å¾—è²¡å ±æ—¥æœŸã€‚"""
    try:
        resp = requests.get(f"{BACKEND_URL}/ticker/{ticker}/earnings", timeout=API_EARNINGS_TIMEOUT)
        resp.raise_for_status()
        return resp.json()
    except requests.RequestException:
        return None


@st.cache_data(ttl=CACHE_TTL_DIVIDEND, show_spinner=False)
def fetch_dividend(ticker: str) -> dict | None:
    """å–å¾—è‚¡æ¯è³‡è¨Šã€‚"""
    try:
        resp = requests.get(f"{BACKEND_URL}/ticker/{ticker}/dividend", timeout=API_DIVIDEND_TIMEOUT)
        resp.raise_for_status()
        return resp.json()
    except requests.RequestException:
        return None


@st.cache_data(ttl=CACHE_TTL_MOAT, show_spinner=False)
def fetch_moat(ticker: str) -> dict | None:
    """å–å¾—è­·åŸæ²³åˆ†æè³‡æ–™ã€‚"""
    return api_get(f"/ticker/{ticker}/moat")


@st.cache_data(ttl=CACHE_TTL_SCAN_HISTORY, show_spinner=False)
def fetch_scan_history(ticker: str, limit: int = SCAN_HISTORY_CARD_LIMIT) -> list | None:
    """å–å¾—æƒææ­·å²ã€‚"""
    return api_get(f"/ticker/{ticker}/scan-history?limit={limit}")


@st.cache_data(ttl=CACHE_TTL_ALERTS, show_spinner=False)
def fetch_alerts(ticker: str) -> list | None:
    """å–å¾—åƒ¹æ ¼è­¦å ±åˆ—è¡¨ã€‚"""
    return api_get(f"/ticker/{ticker}/alerts")


@st.cache_data(ttl=CACHE_TTL_THESIS, show_spinner=False)
def fetch_thesis_history(ticker: str) -> list | None:
    """å–å¾—è§€é»ç‰ˆæ§æ­·å²ã€‚"""
    return api_get(f"/ticker/{ticker}/thesis")


# ---------------------------------------------------------------------------
# Sidebar: æ–°å¢è‚¡ç¥¨ & æƒæ
# ---------------------------------------------------------------------------

with st.sidebar:
    st.header("ğŸ› ï¸ æ“ä½œé¢æ¿")

    # -- æ–°å¢è‚¡ç¥¨ --
    st.subheader("â• æ–°å¢è¿½è¹¤è‚¡ç¥¨")
    with st.form("add_stock_form", clear_on_submit=True):
        new_ticker = st.text_input("è‚¡ç¥¨ä»£è™Ÿ", placeholder="ä¾‹å¦‚ AAPL, TSM, NVDA")
        new_category = st.selectbox(
            "åˆ†é¡",
            options=CATEGORY_OPTIONS,
            format_func=lambda x: CATEGORY_LABELS.get(x, x),
        )
        new_thesis = st.text_area("åˆå§‹è§€é»", placeholder="å¯«ä¸‹ä½ å°é€™æª”è‚¡ç¥¨çš„çœ‹æ³•...")
        new_tags = st.multiselect(
            "ğŸ·ï¸ åˆå§‹æ¨™ç±¤",
            options=DEFAULT_TAG_OPTIONS,
        )
        submitted = st.form_submit_button("æ–°å¢")

        if submitted:
            if not new_ticker.strip():
                st.warning("âš ï¸ è«‹è¼¸å…¥è‚¡ç¥¨ä»£è™Ÿã€‚")
            elif not new_thesis.strip():
                st.warning("âš ï¸ è«‹è¼¸å…¥åˆå§‹è§€é»ã€‚")
            else:
                result = api_post("/ticker", {
                    "ticker": new_ticker.strip().upper(),
                    "category": new_category,
                    "thesis": new_thesis.strip(),
                    "tags": new_tags,
                })
                if result:
                    st.success(f"âœ… å·²æ–°å¢ {new_ticker.upper()} åˆ°è¿½è¹¤æ¸…å–®ï¼")
                    st.rerun()

    st.divider()

    # -- å…¨åŸŸæƒæ (V2 ä¸‰å±¤æ¼æ–—) --
    st.subheader("ğŸ” ä¸‰å±¤æ¼æ–—æƒæ")
    st.caption("æƒæåœ¨èƒŒæ™¯åŸ·è¡Œï¼Œçµæœå°‡é€é Telegram æ¨æ’­é€šçŸ¥ã€‚ç³»çµ±æ¯ 30 åˆ†é˜è‡ªå‹•æƒæä¸€æ¬¡ã€‚")
    if st.button("ğŸš€ åŸ·è¡Œæƒæ", use_container_width=True):
        result = api_post("/scan", {})
        if result:
            st.success(f"âœ… {result.get('message', 'æƒæå·²å•Ÿå‹•')}")

    st.divider()

    # -- åŒ¯å‡ºè§€å¯Ÿåå–® --
    st.subheader("ğŸ“¥ åŒ¯å‡ºè§€å¯Ÿåå–®")
    export_data = api_get("/stocks/export")
    if export_data:
        export_json = json.dumps(export_data, ensure_ascii=False, indent=2)
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ JSON",
            data=export_json,
            file_name=EXPORT_FILENAME,
            mime="application/json",
            use_container_width=True,
        )
        st.caption(f"å…± {len(export_data)} æª”è‚¡ç¥¨ï¼ˆå«è§€é»èˆ‡æ¨™ç±¤ï¼‰")
    else:
        st.caption("ç›®å‰ç„¡è¿½è¹¤è‚¡ç¥¨å¯åŒ¯å‡ºã€‚")

    st.divider()

    # -- åŒ¯å…¥è§€å¯Ÿåå–® --
    st.subheader("ğŸ“¤ åŒ¯å…¥è§€å¯Ÿåå–®")
    uploaded_file = st.file_uploader(
        "ä¸Šå‚³ JSON æª”æ¡ˆ",
        type=["json"],
        key="import_file",
        label_visibility="collapsed",
    )
    if uploaded_file is not None:
        try:
            import_data = json.loads(uploaded_file.getvalue().decode("utf-8"))
            if isinstance(import_data, list):
                st.caption(f"åµæ¸¬åˆ° {len(import_data)} ç­†è³‡æ–™ã€‚")
                if st.button("ğŸ“¤ ç¢ºèªåŒ¯å…¥", use_container_width=True):
                    try:
                        resp = requests.post(
                            f"{BACKEND_URL}/stocks/import",
                            json=import_data,
                            timeout=API_POST_TIMEOUT,
                        )
                        resp.raise_for_status()
                        result = resp.json()
                    except requests.RequestException as e:
                        st.error(f"âŒ åŒ¯å…¥å¤±æ•—ï¼š{e}")
                        result = None
                    if result:
                        st.success(result.get("message", "âœ… åŒ¯å…¥å®Œæˆ"))
                        if result.get("errors"):
                            for err in result["errors"]:
                                st.warning(f"âš ï¸ {err}")
                        st.cache_data.clear()
                        st.rerun()
            else:
                st.warning("âš ï¸ JSON æ ¼å¼éŒ¯èª¤ï¼Œé æœŸç‚ºé™£åˆ—ã€‚")
        except json.JSONDecodeError:
            st.error("âŒ ç„¡æ³•è§£æ JSON æª”æ¡ˆã€‚")

    st.divider()

    # -- é‡æ–°æ•´ç†è³‡æ–™ --
    st.subheader("ğŸ”„ è³‡æ–™å¿«å–")
    st.caption("è‚¡ç¥¨è³‡æ–™å¿«å– 5 åˆ†é˜ï¼ŒéæœŸå¾Œä¸‹æ¬¡æ“ä½œæ™‚è‡ªå‹•é‡æ–°è¼‰å…¥ã€‚é»æ“Šä¸‹æ–¹æŒ‰éˆ•å¯ç«‹å³åˆ·æ–°ã€‚")
    if st.button("ğŸ”„ ç«‹å³åˆ·æ–°è³‡æ–™", use_container_width=True):
        st.cache_data.clear()
        st.rerun()


# ---------------------------------------------------------------------------
# Main Dashboard: è‚¡ç¥¨æ¸…å–® (Tabs)
# ---------------------------------------------------------------------------

stocks_data = fetch_stocks()
removed_data = fetch_removed_stocks()

if stocks_data is None:
    st.info("â³ ç„¡æ³•é€£ç·šè‡³å¾Œç«¯æœå‹™ï¼Œè«‹ç¢ºèª Backend æ˜¯å¦å•Ÿå‹•ã€‚")
    st.stop()

# ä¾åˆ†é¡åˆ†çµ„
category_map = {
    "Trend_Setter": [],
    "Moat": [],
    "Growth": [],
    "ETF": [],
}
for stock in (stocks_data or []):
    cat = stock.get("category", "Growth")
    if cat in category_map:
        category_map[cat].append(stock)

removed_list = removed_data or []

tab_trend, tab_moat, tab_growth, tab_etf, tab_archive = st.tabs([
    f"ğŸŒŠ é¢¨å‘çƒ ({len(category_map['Trend_Setter'])})",
    f"ğŸ° è­·åŸæ²³ ({len(category_map['Moat'])})",
    f"ğŸš€ æˆé•·å¤¢æƒ³ ({len(category_map['Growth'])})",
    f"ğŸ§º ETF ({len(category_map['ETF'])})",
    f"ğŸ“¦ å·²ç§»é™¤ ({len(removed_list)})",
])


def render_thesis_history(history: list[dict]) -> None:
    """æ¸²æŸ“è§€é»ç‰ˆæ§æ­·å²ç´€éŒ„ï¼ˆå…±ç”¨æ–¼ä¸»å¡ç‰‡èˆ‡å·²ç§»é™¤å¡ç‰‡ï¼‰ã€‚"""
    if history:
        st.markdown("**ğŸ“œ æ­·å²è§€é»ç´€éŒ„ï¼š**")
        for entry in history:
            ver = entry.get("version", "?")
            content = entry.get("content", "")
            created = entry.get("created_at", "")
            entry_tags = entry.get("tags", [])
            st.markdown(
                f"**v{ver}** ({created[:10] if created else 'æœªçŸ¥æ—¥æœŸ'})"
            )
            if entry_tags:
                st.caption(
                    "æ¨™ç±¤ï¼š" + " ".join(f"`{t}`" for t in entry_tags)
                )
            st.text(content)
            st.divider()
    else:
        st.caption("å°šç„¡æ­·å²è§€é»ç´€éŒ„ã€‚")


def render_stock_card(stock: dict) -> None:
    """æ¸²æŸ“å–®ä¸€è‚¡ç¥¨å¡ç‰‡ï¼ŒåŒ…å«æŠ€è¡“æŒ‡æ¨™èˆ‡è§€é»ç·¨è¼¯ã€‚"""
    ticker = stock["ticker"]
    signals = fetch_signals(ticker) or {}

    with st.container(border=True):
        col1, col2 = st.columns([1, 2])

        with col1:
            st.subheader(f"ğŸ“Š {ticker}")
            st.caption(f"åˆ†é¡ï¼š{stock['category']}")

            # å‹•æ…‹æ¨™ç±¤
            current_tags = stock.get("current_tags", [])
            if current_tags:
                tag_badges = " ".join(
                    f"`{tag}`" for tag in current_tags
                )
                st.markdown(f"ğŸ·ï¸ {tag_badges}")

            if "error" in signals:
                st.warning(signals["error"])
            else:
                price = signals.get("price", "N/A")
                rsi = signals.get("rsi", "N/A")
                ma200 = signals.get("ma200", "N/A")
                ma60 = signals.get("ma60", "N/A")
                bias = signals.get("bias")
                volume_ratio = signals.get("volume_ratio")

                metrics_col1, metrics_col2 = st.columns(2)
                with metrics_col1:
                    st.metric("ç¾åƒ¹", f"${price}")
                    st.metric("RSI(14)", rsi)
                with metrics_col2:
                    st.metric("200MA", f"${ma200}" if ma200 else "N/A")
                    st.metric("60MA", f"${ma60}" if ma60 else "N/A")

                # ç±Œç¢¼é¢æŒ‡æ¨™
                chip_col1, chip_col2 = st.columns(2)
                with chip_col1:
                    if bias is not None:
                        bias_color = "ğŸ”´" if bias > BIAS_OVERHEATED_UI else ("ğŸŸ¢" if bias < BIAS_OVERSOLD_UI else "âšª")
                        st.metric(f"{bias_color} ä¹–é›¢ç‡ Bias", f"{bias}%")
                    else:
                        st.metric("ä¹–é›¢ç‡ Bias", "N/A")
                with chip_col2:
                    if volume_ratio is not None:
                        st.metric("é‡æ¯” Vol Ratio", f"{volume_ratio}x")
                    else:
                        st.metric("é‡æ¯” Vol Ratio", "N/A")

                # ç‹€æ…‹åˆ—è¡¨
                for s in signals.get("status", []):
                    st.write(s)

            # -- è²¡å ±æ—¥æ›† & è‚¡æ¯ --
            info_cols = st.columns(2)
            earnings_data = fetch_earnings(ticker)
            earnings_date_str = (
                earnings_data.get("earnings_date") if earnings_data else None
            )
            with info_cols[0]:
                if earnings_date_str:
                    from datetime import datetime as dt
                    try:
                        ed = dt.strptime(earnings_date_str, "%Y-%m-%d")
                        days_left = (ed - dt.now()).days
                        badge = f" ({days_left}å¤©)" if 0 < days_left <= EARNINGS_BADGE_DAYS_THRESHOLD else ""
                        st.caption(f"ğŸ“… è²¡å ±æ—¥ï¼š{earnings_date_str}{badge}")
                    except ValueError:
                        st.caption(f"ğŸ“… è²¡å ±æ—¥ï¼š{earnings_date_str}")
                else:
                    st.caption("ğŸ“… è²¡å ±æ—¥ï¼šN/A")

            cat = stock.get("category", "")
            with info_cols[1]:
                if cat in ("Moat", "ETF"):
                    div_data = fetch_dividend(ticker)
                    if div_data and div_data.get("dividend_yield"):
                        dy = div_data["dividend_yield"]
                        ex_date = div_data.get("ex_dividend_date", "N/A")
                        st.caption(f"ğŸ’° æ®–åˆ©ç‡ï¼š{dy}% | é™¤æ¯æ—¥ï¼š{ex_date}")
                    else:
                        st.caption("ğŸ’° æ®–åˆ©ç‡ï¼šN/A")

            # -- ç±Œç¢¼é¢ (13F) --
            with st.expander(f"ğŸ³ ç±Œç¢¼é¢ (13F) â€” {ticker}", expanded=False):
                st.link_button(
                    f"ğŸ³ å‰å¾€ WhaleWisdom æŸ¥çœ‹å¤§æˆ¶å‹•å‘",
                    WHALEWISDOM_STOCK_URL.format(ticker=ticker.lower()),
                    use_container_width=True,
                )
                st.caption(
                    "ğŸ’¡ æŠ•è³‡å¿ƒæ³•ï¼šé»æ“ŠæŒ‰éˆ•æŸ¥çœ‹æ©Ÿæ§‹æŒå€‰ã€‚é‡é»è§€å¯Ÿ"
                    "æ³¢å…‹å¤ (Berkshire)ã€æ©‹æ°´ (Bridgewater) ç­‰å¤§åŸºé‡‘"
                    "æ˜¯ 'New Buy/Add' (ä½ˆå±€) é‚„æ˜¯ 'Sold Out' (é›¢å ´)ã€‚"
                    "è·Ÿå–®è¦è·Ÿã€Œæ–°å¢ã€è€Œéåº«å­˜ã€‚"
                )

                holders = signals.get("institutional_holders")
                if holders and isinstance(holders, list) and len(holders) > 0:
                    st.markdown("**ğŸ“Š å‰äº”å¤§æ©Ÿæ§‹æŒæœ‰è€…ï¼š**")
                    st.dataframe(holders, use_container_width=True, hide_index=True)
                else:
                    st.info(
                        "âš ï¸ æ©Ÿæ§‹æŒå€‰è³‡æ–™æš«æ™‚ç„¡æ³•å–å¾—ï¼Œè«‹é»æ“Šä¸Šæ–¹æŒ‰éˆ•å‰å¾€ WhaleWisdom æŸ¥çœ‹å®Œæ•´ 13F å ±å‘Šã€‚"
                    )

            # -- è­·åŸæ²³æª¢æ¸¬ (Moat Health Check) -- ETF ä¸é©ç”¨
            if stock.get("category") != "ETF":
                with st.expander(f"ğŸ° è­·åŸæ²³æª¢æ¸¬ â€” {ticker}", expanded=False):
                    moat_data = fetch_moat(ticker)

                    if moat_data and moat_data.get("moat") != "N/A":
                        # 1) æ¯›åˆ©ç‡æŒ‡æ¨™ + YoY è®ŠåŒ–
                        curr_margin = moat_data.get("current_margin")
                        margin_change = moat_data.get("change")

                        if curr_margin is not None and margin_change is not None:
                            st.metric(
                                "æœ€æ–°æ¯›åˆ©ç‡ (Gross Margin)",
                                f"{curr_margin:.1f}%",
                                delta=f"{margin_change:+.2f} pp (YoY)",
                            )
                        else:
                            st.metric("æœ€æ–°æ¯›åˆ©ç‡ (Gross Margin)", "N/A")

                        # 2) 5 å­£èµ°å‹¢æŠ˜ç·šåœ–
                        trend = moat_data.get("margin_trend", [])
                        valid_trend = [t for t in trend if t.get("value") is not None]
                        if valid_trend:
                            df = pd.DataFrame(valid_trend).set_index("date")
                            df.columns = ["æ¯›åˆ©ç‡ (%)"]
                            st.line_chart(df)
                        else:
                            st.caption("âš ï¸ æ¯›åˆ©ç‡è¶¨å‹¢è³‡æ–™ä¸è¶³ï¼Œç„¡æ³•ç¹ªåœ–ã€‚")

                        # 3) æŠ•è³‡è¨ºæ–· (Azusa Diagnosis)
                        bias_val = signals.get("bias")
                        price_is_weak = bias_val is not None and bias_val < PRICE_WEAK_BIAS_THRESHOLD
                        margin_is_strong = (
                            margin_change is not None and margin_change > 0
                        )
                        margin_is_bad = (
                            margin_change is not None and margin_change < MARGIN_BAD_CHANGE_THRESHOLD
                        )

                        if margin_is_bad:
                            st.error(
                                "ğŸ”´ **è­¦å ± (Thesis Broken)**ï¼š"
                                "è­·åŸæ²³å—æï¼ˆæ¯›åˆ© YoY è¡°é€€è¶…é 2 å€‹ç™¾åˆ†é»ï¼‰ï¼Œ"
                                "åŸºæœ¬é¢è½‰å·®ï¼Œå‹¿æ¥åˆ€ã€‚"
                            )
                        elif price_is_weak and margin_is_strong:
                            st.success(
                                "ğŸŸ¢ **éŒ¯æ®ºæ©Ÿæœƒ (Contrarian Buy)**ï¼š"
                                "è‚¡åƒ¹å›æª”ä½†è­·åŸæ²³è®Šå¯¬ï¼ˆæ¯›åˆ©å‡ï¼‰ï¼Œ"
                                "åŸºæœ¬é¢å¼·å‹ï¼Œå¯ç•™æ„ä½ˆå±€æ™‚æ©Ÿã€‚"
                            )
                        elif margin_is_strong:
                            st.success(
                                "ğŸŸ¢ **è­·åŸæ²³ç©©å›º**ï¼š"
                                "æ¯›åˆ©ç‡ YoY æˆé•·ï¼ŒåŸºæœ¬é¢å¥åº·ã€‚"
                            )
                        elif price_is_weak:
                            st.warning(
                                "ğŸŸ¡ **è‚¡åƒ¹åå¼±**ï¼š"
                                "ä¹–é›¢ç‡åä½ä½†è­·åŸæ²³æ•¸æ“šæŒå¹³ï¼Œç•™æ„å¾ŒçºŒå­£å ±ã€‚"
                            )
                        else:
                            st.info("âšª **è§€å¯Ÿä¸­**ï¼šè­·åŸæ²³æ•¸æ“šæŒå¹³ï¼ŒæŒçºŒè§€å¯Ÿã€‚")

                        # è£œå……è©³æƒ…
                        details = moat_data.get("details", "")
                        if details:
                            st.caption(f"ğŸ“Š {details}")
                    else:
                        st.warning(
                            "âš ï¸ ç„¡æ³•å–å¾—è²¡å ±æ•¸æ“šï¼ˆå¯èƒ½æ˜¯æ–°è‚¡ï¼‰ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
                        )

            # -- æƒææ­·å² --
            with st.expander(f"ğŸ“ˆ æƒææ­·å² â€” {ticker}", expanded=False):
                scan_hist = fetch_scan_history(ticker)
                if scan_hist:
                    # è¨ˆç®—é€£çºŒæ¬¡æ•¸
                    latest_sig = scan_hist[0].get("signal", "NORMAL")
                    consecutive = 1
                    for i in range(1, len(scan_hist)):
                        if scan_hist[i].get("signal") == latest_sig:
                            consecutive += 1
                        else:
                            break
                    if latest_sig != "NORMAL" and consecutive > 1:
                        st.warning(f"âš ï¸ {latest_sig} å·²é€£çºŒ {consecutive} æ¬¡æƒæ")

                    for entry in scan_hist:
                        sig = entry.get("signal", "NORMAL")
                        scanned = entry.get("scanned_at", "")
                        sig_icon = {
                            "THESIS_BROKEN": "ğŸ”´",
                            "CONTRARIAN_BUY": "ğŸŸ¢",
                            "OVERHEATED": "ğŸŸ ",
                            "NORMAL": "âšª",
                        }.get(sig, "âšª")
                        date_str = scanned[:16] if scanned else "N/A"
                        st.caption(f"{sig_icon} {sig} â€” {date_str}")
                else:
                    st.caption("å°šç„¡æƒæç´€éŒ„ã€‚")

            # -- è‡ªè¨‚åƒ¹æ ¼è­¦å ± --
            with st.expander(f"ğŸ”” åƒ¹æ ¼è­¦å ± â€” {ticker}", expanded=False):
                alerts = fetch_alerts(ticker)
                if alerts:
                    st.markdown("**ç›®å‰è­¦å ±ï¼š**")
                    for a in alerts:
                        op_str = "<" if a["operator"] == "lt" else ">"
                        active_badge = "ğŸŸ¢" if a["is_active"] else "âšª"
                        triggered = a.get("last_triggered_at")
                        trigger_info = (
                            f"ï¼ˆä¸Šæ¬¡è§¸ç™¼ï¼š{triggered[:10]}ï¼‰" if triggered else ""
                        )
                        col_a, col_b = st.columns([3, 1])
                        with col_a:
                            st.caption(
                                f"{active_badge} {a['metric']} {op_str} "
                                f"{a['threshold']}{trigger_info}"
                            )
                        with col_b:
                            if st.button(
                                "ğŸ—‘ï¸",
                                key=f"del_alert_{a['id']}",
                                help="åˆªé™¤æ­¤è­¦å ±",
                            ):
                                api_delete(f"/alerts/{a['id']}")
                                st.rerun()
                    st.divider()

                st.markdown("**â• æ–°å¢è­¦å ±ï¼š**")
                alert_cols = st.columns(3)
                with alert_cols[0]:
                    alert_metric = st.selectbox(
                        "æŒ‡æ¨™",
                        options=["rsi", "price", "bias"],
                        key=f"alert_metric_{ticker}",
                        label_visibility="collapsed",
                    )
                with alert_cols[1]:
                    alert_op = st.selectbox(
                        "æ¢ä»¶",
                        options=["lt", "gt"],
                        format_func=lambda x: "<ï¼ˆå°æ–¼ï¼‰" if x == "lt" else ">ï¼ˆå¤§æ–¼ï¼‰",
                        key=f"alert_op_{ticker}",
                        label_visibility="collapsed",
                    )
                with alert_cols[2]:
                    alert_threshold = st.number_input(
                        "é–€æª»",
                        value=DEFAULT_ALERT_THRESHOLD,
                        step=1.0,
                        key=f"alert_threshold_{ticker}",
                        label_visibility="collapsed",
                    )

                if st.button("æ–°å¢è­¦å ±", key=f"add_alert_{ticker}"):
                    result = api_post(
                        f"/ticker/{ticker}/alerts",
                        {
                            "metric": alert_metric,
                            "operator": alert_op,
                            "threshold": alert_threshold,
                        },
                    )
                    if result:
                        st.success(result.get("message", "âœ… è­¦å ±å·²å»ºç«‹"))
                        st.rerun()

        with col2:
            st.markdown("**ğŸ’¡ ç•¶å‰è§€é»ï¼š**")
            st.info(stock.get("current_thesis", "å°šç„¡è§€é»"))

            # -- è§€é»æ­·å²èˆ‡ç·¨è¼¯ --
            with st.expander(f"ğŸ“ è§€é»ç‰ˆæ§ â€” {ticker}", expanded=False):
                # å–å¾—æ­·å²ç´€éŒ„
                history = fetch_thesis_history(ticker)

                render_thesis_history(history or [])

                # æ–°å¢è§€é»
                st.markdown("**âœï¸ æ–°å¢è§€é»ï¼š**")
                new_thesis_content = st.text_area(
                    "è§€é»å…§å®¹",
                    key=f"thesis_input_{ticker}",
                    placeholder="å¯«ä¸‹ä½ å°é€™æª”è‚¡ç¥¨çš„æœ€æ–°çœ‹æ³•...",
                    label_visibility="collapsed",
                )

                # æ¨™ç±¤ç·¨è¼¯
                all_tag_options = sorted(
                    set(DEFAULT_TAG_OPTIONS + current_tags)
                )
                selected_tags = st.multiselect(
                    "ğŸ·ï¸ è¨­å®šé ˜åŸŸæ¨™ç±¤",
                    options=all_tag_options,
                    default=current_tags,
                    key=f"tag_select_{ticker}",
                )

                if st.button("æ›´æ–°è§€é»", key=f"thesis_btn_{ticker}"):
                    if new_thesis_content.strip():
                        result = api_post(
                            f"/ticker/{ticker}/thesis",
                            {
                                "content": new_thesis_content.strip(),
                                "tags": selected_tags,
                            },
                        )
                        if result:
                            st.success(result.get("message", "âœ… è§€é»å·²æ›´æ–°"))
                            st.cache_data.clear()
                            st.rerun()
                    else:
                        st.warning("âš ï¸ è«‹è¼¸å…¥è§€é»å…§å®¹ã€‚")

            # -- åˆ‡æ›åˆ†é¡ --
            with st.expander(f"ğŸ”„ åˆ‡æ›åˆ†é¡ â€” {ticker}", expanded=False):
                current_cat = stock.get("category", "Growth")
                other_categories = [c for c in CATEGORY_OPTIONS if c != current_cat]

                current_label = CATEGORY_LABELS.get(current_cat, current_cat)
                st.caption(f"ç›®å‰åˆ†é¡ï¼š**{current_label}**")

                new_cat = st.selectbox(
                    "æ–°åˆ†é¡",
                    options=other_categories,
                    format_func=lambda x: CATEGORY_LABELS.get(x, x),
                    key=f"cat_select_{ticker}",
                    label_visibility="collapsed",
                )
                if st.button("ç¢ºèªåˆ‡æ›", key=f"cat_btn_{ticker}"):
                    result = api_patch(
                        f"/ticker/{ticker}/category",
                        {"category": new_cat},
                    )
                    if result:
                        st.success(result.get("message", "âœ… åˆ†é¡å·²åˆ‡æ›"))
                        st.cache_data.clear()
                        st.rerun()

            # -- ç§»é™¤è¿½è¹¤ --
            with st.expander(f"ğŸ—‘ï¸ ç§»é™¤è¿½è¹¤ â€” {ticker}", expanded=False):
                st.warning("âš ï¸ ç§»é™¤å¾Œè‚¡ç¥¨å°‡ç§»è‡³ã€Œå·²ç§»é™¤ã€åˆ†é ï¼Œå¯éš¨æ™‚æŸ¥é–±æ­·å²ç´€éŒ„ã€‚")
                removal_reason = st.text_area(
                    "ç§»é™¤åŸå› ",
                    key=f"removal_input_{ticker}",
                    placeholder="å¯«ä¸‹ä½ ç§»é™¤é€™æª”è‚¡ç¥¨çš„åŸå› ...",
                    label_visibility="collapsed",
                )
                if st.button("ç¢ºèªç§»é™¤", key=f"removal_btn_{ticker}", type="primary"):
                    if removal_reason.strip():
                        result = api_post(
                            f"/ticker/{ticker}/deactivate",
                            {"reason": removal_reason.strip()},
                        )
                        if result:
                            st.success(result.get("message", "âœ… å·²ç§»é™¤"))
                            st.rerun()
                    else:
                        st.warning("âš ï¸ è«‹è¼¸å…¥ç§»é™¤åŸå› ã€‚")


def render_reorder_section(category_key: str, stocks_in_cat: list[dict]) -> None:
    """æ¸²æŸ“æ‹–æ›³æ’åºå€å¡Šã€‚"""
    if len(stocks_in_cat) < 2:
        return
    with st.expander("â†•ï¸ æ‹–æ›³æ’åº", expanded=False):
        ticker_list = [s["ticker"] for s in stocks_in_cat]
        sorted_tickers = sort_items(ticker_list, key=f"sort_{category_key}")
        if sorted_tickers != ticker_list:
            if st.button("ğŸ’¾ å„²å­˜æ’åº", key=f"save_order_{category_key}"):
                result = api_put("/stocks/reorder", {"ordered_tickers": sorted_tickers})
                if result:
                    st.success(result.get("message", "âœ… æ’åºå·²å„²å­˜"))
                    st.cache_data.clear()
                    st.rerun()
        else:
            st.caption("æ‹–æ›³è‚¡ç¥¨ä»£è™Ÿä»¥èª¿æ•´é¡¯ç¤ºé †åºã€‚")


# -- æ¸²æŸ“å„ Tabï¼ˆè¿´åœˆåŒ–ï¼‰ --
_category_tabs = [tab_trend, tab_moat, tab_growth, tab_etf]
for _cat, _tab in zip(CATEGORY_OPTIONS, _category_tabs):
    with _tab:
        _stocks = category_map[_cat]
        if _stocks:
            render_reorder_section(_cat, _stocks)
            for stock in _stocks:
                render_stock_card(stock)
        else:
            st.info(f"ğŸ“­ å°šç„¡{CATEGORY_LABELS[_cat]}é¡è‚¡ç¥¨ï¼Œè«‹åœ¨å·¦å´é¢æ¿æ–°å¢ã€‚")

with tab_archive:
    if removed_list:
        for removed in removed_list:
            ticker = removed["ticker"]
            with st.container(border=True):
                col1, col2 = st.columns([1, 2])

                with col1:
                    st.subheader(f"ğŸ“¦ {ticker}")
                    category_label = CATEGORY_LABELS.get(
                        removed.get("category", ""), removed.get("category", "")
                    )
                    st.caption(f"åˆ†é¡ï¼š{category_label}")
                    removed_at = removed.get("removed_at", "")
                    st.caption(f"ç§»é™¤æ—¥æœŸï¼š{removed_at[:10] if removed_at else 'æœªçŸ¥'}")

                with col2:
                    st.markdown("**ğŸ—‘ï¸ ç§»é™¤åŸå› ï¼š**")
                    st.error(removed.get("removal_reason", "æœªçŸ¥"))

                    st.markdown("**ğŸ’¡ æœ€å¾Œè§€é»ï¼š**")
                    st.info(removed.get("current_thesis", "å°šç„¡è§€é»"))

                    # -- ç§»é™¤æ­·å² --
                    with st.expander(f"ğŸ“œ ç§»é™¤æ­·å² â€” {ticker}", expanded=False):
                        removals = api_get(f"/ticker/{ticker}/removals")
                        if removals:
                            for entry in removals:
                                created = entry.get("created_at", "")
                                st.markdown(
                                    f"**{created[:10] if created else 'æœªçŸ¥æ—¥æœŸ'}**"
                                )
                                st.text(entry.get("reason", ""))
                                st.divider()
                        else:
                            st.caption("å°šç„¡ç§»é™¤æ­·å²ç´€éŒ„ã€‚")

                    # -- è§€é»æ­·å² --
                    with st.expander(f"ğŸ“ è§€é»æ­·å² â€” {ticker}", expanded=False):
                        history = fetch_thesis_history(ticker)
                        render_thesis_history(history or [])

                    # -- é‡æ–°å•Ÿç”¨ --
                    with st.expander(f"ğŸ”„ é‡æ–°å•Ÿç”¨ â€” {ticker}", expanded=False):
                        reactivate_cat = st.selectbox(
                            "åˆ†é¡",
                            options=CATEGORY_OPTIONS,
                            format_func=lambda x: CATEGORY_LABELS.get(x, x),
                            key=f"reactivate_cat_{ticker}",
                        )
                        reactivate_thesis = st.text_area(
                            "æ–°è§€é»ï¼ˆé¸å¡«ï¼‰",
                            key=f"reactivate_thesis_{ticker}",
                            placeholder="é‡æ–°å•Ÿç”¨æ™‚çš„è§€é»...",
                        )
                        if st.button(
                            "âœ… ç¢ºèªé‡æ–°å•Ÿç”¨",
                            key=f"reactivate_btn_{ticker}",
                            type="primary",
                        ):
                            payload = {"category": reactivate_cat}
                            if reactivate_thesis.strip():
                                payload["thesis"] = reactivate_thesis.strip()
                            result = api_post(
                                f"/ticker/{ticker}/reactivate", payload
                            )
                            if result:
                                st.success(result.get("message", "âœ… å·²é‡æ–°å•Ÿç”¨"))
                                st.cache_data.clear()
                                st.rerun()
    else:
        st.info("ğŸ“­ ç›®å‰æ²’æœ‰å·²ç§»é™¤çš„è‚¡ç¥¨ã€‚")
