"""
Application â€” Service Layer (Use Cases)ã€‚
ç·¨æ’æ¥­å‹™æµç¨‹ï¼Œå”èª¿ Repository èˆ‡ Infrastructure Adapterã€‚
ä¸åŒ…å« HTTP/æ¡†æ¶é‚è¼¯ã€‚
"""

import json
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta, timezone

from sqlmodel import Session

from domain.analysis import determine_scan_signal
from domain.constants import (
    ETF_MOAT_NA_MESSAGE,
    PRICE_ALERT_COOLDOWN_HOURS,
    SCAN_HISTORY_DEFAULT_LIMIT,
    SCAN_THREAD_POOL_SIZE,
    WEEKLY_DIGEST_LOOKBACK_DAYS,
)
from domain.entities import PriceAlert, RemovalLog, ScanLog, Stock, ThesisLog
from domain.enums import CATEGORY_LABEL, MoatStatus, ScanSignal, StockCategory
from infrastructure import repositories as repo
from infrastructure.market_data import (
    analyze_market_sentiment,
    analyze_moat_trend,
    get_technical_signals,
)
from infrastructure.notification import send_telegram_message
from logging_config import get_logger

logger = get_logger(__name__)


# ---------------------------------------------------------------------------
# Tag è½‰æ›å·¥å…·
# ---------------------------------------------------------------------------


def _tags_to_str(tags: list[str]) -> str:
    """å°‡æ¨™ç±¤åˆ—è¡¨è½‰ç‚ºé€—è™Ÿåˆ†éš”å­—ä¸²å­˜å…¥ DBã€‚"""
    return ",".join(t.strip() for t in tags if t.strip())


def _str_to_tags(s: str) -> list[str]:
    """å°‡ DB ä¸­çš„é€—è™Ÿåˆ†éš”å­—ä¸²è½‰ç‚ºæ¨™ç±¤åˆ—è¡¨ã€‚"""
    return [t.strip() for t in s.split(",") if t.strip()] if s else []


# ===========================================================================
# Stock Service
# ===========================================================================


class StockNotFoundError(Exception):
    """è‚¡ç¥¨ä¸å­˜åœ¨ã€‚"""


class StockAlreadyExistsError(Exception):
    """è‚¡ç¥¨å·²å­˜åœ¨ã€‚"""


class StockAlreadyInactiveError(Exception):
    """è‚¡ç¥¨å·²æ˜¯åœç”¨ç‹€æ…‹ã€‚"""


class StockAlreadyActiveError(Exception):
    """è‚¡ç¥¨å·²æ˜¯å•Ÿç”¨ç‹€æ…‹ã€‚"""


class CategoryUnchangedError(Exception):
    """åˆ†é¡ç›¸åŒï¼Œç„¡éœ€è®Šæ›´ã€‚"""


def create_stock(
    session: Session,
    ticker: str,
    category: StockCategory,
    thesis: str,
    tags: list[str] | None = None,
) -> Stock:
    """
    æ–°å¢è‚¡ç¥¨åˆ°è¿½è¹¤æ¸…å–®ï¼ŒåŒæ™‚å»ºç«‹ç¬¬ä¸€ç­†è§€é»ç´€éŒ„ã€‚
    """
    ticker_upper = ticker.upper()
    tags = tags or []
    tags_str = _tags_to_str(tags)
    logger.info("æ–°å¢è‚¡ç¥¨ï¼š%sï¼ˆåˆ†é¡ï¼š%sï¼Œæ¨™ç±¤ï¼š%sï¼‰", ticker_upper, category.value, tags)

    existing = repo.find_stock_by_ticker(session, ticker_upper)
    if existing:
        raise StockAlreadyExistsError(f"è‚¡ç¥¨ {ticker_upper} å·²å­˜åœ¨è¿½è¹¤æ¸…å–®ä¸­ã€‚")

    stock = Stock(
        ticker=ticker_upper,
        category=category,
        current_thesis=thesis,
        current_tags=tags_str,
        is_active=True,
    )
    session.add(stock)

    thesis_log = ThesisLog(
        stock_ticker=ticker_upper,
        content=thesis,
        tags=tags_str,
        version=1,
    )
    repo.create_thesis_log(session, thesis_log)

    session.commit()
    session.refresh(stock)

    logger.info("è‚¡ç¥¨ %s å·²æˆåŠŸæ–°å¢è‡³è¿½è¹¤æ¸…å–®ã€‚", ticker_upper)
    return stock


def list_active_stocks(session: Session) -> list[dict]:
    """å–å¾—æ‰€æœ‰å•Ÿç”¨ä¸­çš„è¿½è¹¤è‚¡ç¥¨ï¼ˆåƒ… DB è³‡æ–™ï¼Œä¸å«æŠ€è¡“è¨Šè™Ÿï¼‰ã€‚"""
    logger.info("å–å¾—æ‰€æœ‰è¿½è¹¤è‚¡ç¥¨æ¸…å–®...")
    stocks = repo.find_active_stocks(session)
    logger.info("å…± %d æª”è¿½è¹¤ä¸­è‚¡ç¥¨ã€‚", len(stocks))

    return [
        {
            "ticker": stock.ticker,
            "category": stock.category,
            "current_thesis": stock.current_thesis,
            "current_tags": _str_to_tags(stock.current_tags),
            "display_order": stock.display_order,
            "is_active": stock.is_active,
        }
        for stock in stocks
    ]


def update_stock_category(session: Session, ticker: str, new_category: StockCategory) -> dict:
    """
    åˆ‡æ›è‚¡ç¥¨åˆ†é¡ï¼Œä¸¦åœ¨è§€é»æ­·å²ä¸­è¨˜éŒ„è®Šæ›´ã€‚
    """
    ticker_upper = ticker.upper()
    logger.info("åˆ†é¡è®Šæ›´è«‹æ±‚ï¼š%s â†’ %s", ticker_upper, new_category.value)

    stock = repo.find_stock_by_ticker(session, ticker_upper)
    if not stock:
        raise StockNotFoundError(f"æ‰¾ä¸åˆ°è‚¡ç¥¨ {ticker_upper}ã€‚")

    old_category = stock.category
    if old_category == new_category:
        old_label = CATEGORY_LABEL.get(old_category.value, old_category.value)
        raise CategoryUnchangedError(f"è‚¡ç¥¨ {ticker_upper} å·²ç¶“æ˜¯ {old_label} åˆ†é¡ã€‚")

    stock.category = new_category
    repo.update_stock(session, stock)

    # å¯©è¨ˆç´€éŒ„
    max_version = repo.get_max_thesis_version(session, ticker_upper)
    old_label = CATEGORY_LABEL.get(old_category.value, old_category.value)
    new_label = CATEGORY_LABEL.get(new_category.value, new_category.value)

    thesis_log = ThesisLog(
        stock_ticker=ticker_upper,
        content=f"[åˆ†é¡è®Šæ›´] {old_label} â†’ {new_label}",
        version=max_version + 1,
    )
    repo.create_thesis_log(session, thesis_log)

    session.commit()
    logger.info("è‚¡ç¥¨ %s åˆ†é¡å·²å¾ %s è®Šæ›´ç‚º %sã€‚", ticker_upper, old_label, new_label)

    return {
        "message": f"âœ… {ticker_upper} åˆ†é¡å·²å¾ã€Œ{old_label}ã€è®Šæ›´ç‚ºã€Œ{new_label}ã€ã€‚",
        "old_category": old_category.value,
        "new_category": new_category.value,
    }


def deactivate_stock(session: Session, ticker: str, reason: str) -> dict:
    """
    ç§»é™¤è¿½è¹¤è‚¡ç¥¨ï¼Œè¨˜éŒ„ç§»é™¤åŸå› èˆ‡è§€é»ç‰ˆæ§ã€‚
    """
    ticker_upper = ticker.upper()
    logger.info("ç§»é™¤è¿½è¹¤ï¼š%s", ticker_upper)

    stock = repo.find_stock_by_ticker(session, ticker_upper)
    if not stock:
        raise StockNotFoundError(f"æ‰¾ä¸åˆ°è‚¡ç¥¨ {ticker_upper}ã€‚")
    if not stock.is_active:
        raise StockAlreadyInactiveError(f"è‚¡ç¥¨ {ticker_upper} å·²ç¶“æ˜¯ç§»é™¤ç‹€æ…‹ã€‚")

    stock.is_active = False
    repo.update_stock(session, stock)

    removal_log = RemovalLog(stock_ticker=ticker_upper, reason=reason)
    repo.create_removal_log(session, removal_log)

    max_version = repo.get_max_thesis_version(session, ticker_upper)
    thesis_log = ThesisLog(
        stock_ticker=ticker_upper,
        content=f"[å·²ç§»é™¤] {reason}",
        version=max_version + 1,
    )
    repo.create_thesis_log(session, thesis_log)

    session.commit()
    logger.info("è‚¡ç¥¨ %s å·²ç§»é™¤è¿½è¹¤ï¼ˆåŸå› ï¼š%sï¼‰ã€‚", ticker_upper, reason)

    return {"message": f"âœ… {ticker_upper} å·²å¾è¿½è¹¤æ¸…å–®ç§»é™¤ã€‚", "reason": reason}


def reactivate_stock(
    session: Session,
    ticker: str,
    category: StockCategory | None = None,
    thesis: str | None = None,
) -> dict:
    """
    é‡æ–°å•Ÿç”¨å·²ç§»é™¤çš„è‚¡ç¥¨ã€‚å¯é¸æ“‡æ€§æ›´æ–°åˆ†é¡èˆ‡è§€é»ã€‚
    """
    ticker_upper = ticker.upper()
    logger.info("é‡æ–°å•Ÿç”¨è¿½è¹¤ï¼š%s", ticker_upper)

    stock = repo.find_stock_by_ticker(session, ticker_upper)
    if not stock:
        raise StockNotFoundError(f"æ‰¾ä¸åˆ°è‚¡ç¥¨ {ticker_upper}ã€‚")
    if stock.is_active:
        raise StockAlreadyActiveError(f"è‚¡ç¥¨ {ticker_upper} å·²ç¶“æ˜¯å•Ÿç”¨ç‹€æ…‹ã€‚")

    stock.is_active = True
    stock.last_scan_signal = "NORMAL"
    if category:
        stock.category = category
    repo.update_stock(session, stock)

    # è§€é»ç‰ˆæ§ç´€éŒ„
    max_version = repo.get_max_thesis_version(session, ticker_upper)
    thesis_content = thesis or "[é‡æ–°å•Ÿç”¨è¿½è¹¤]"
    thesis_log = ThesisLog(
        stock_ticker=ticker_upper,
        content=thesis_content,
        version=max_version + 1,
    )
    repo.create_thesis_log(session, thesis_log)

    if thesis:
        stock.current_thesis = thesis
        repo.update_stock(session, stock)

    session.commit()
    logger.info("è‚¡ç¥¨ %s å·²é‡æ–°å•Ÿç”¨è¿½è¹¤ã€‚", ticker_upper)

    return {"message": f"âœ… {ticker_upper} å·²é‡æ–°å•Ÿç”¨è¿½è¹¤ã€‚"}


def export_stocks(session: Session) -> list[dict]:
    """åŒ¯å‡ºæ‰€æœ‰å•Ÿç”¨ä¸­è‚¡ç¥¨ï¼ˆç²¾ç°¡æ ¼å¼ï¼Œé©ç”¨æ–¼ JSON ä¸‹è¼‰èˆ‡åŒ¯å…¥ï¼‰ã€‚"""
    logger.info("åŒ¯å‡ºæ‰€æœ‰è¿½è¹¤è‚¡ç¥¨...")
    stocks = repo.find_active_stocks(session)
    return [
        {
            "ticker": stock.ticker,
            "category": stock.category.value,
            "thesis": stock.current_thesis,
            "tags": _str_to_tags(stock.current_tags),
        }
        for stock in stocks
    ]


def update_display_order(session: Session, ordered_tickers: list[str]) -> dict:
    """æ‰¹æ¬¡æ›´æ–°è‚¡ç¥¨é¡¯ç¤ºé †ä½ï¼ˆå–®ä¸€ SELECT + æ‰¹æ¬¡å¯«å…¥ï¼‰ã€‚"""
    logger.info("æ›´æ–°é¡¯ç¤ºé †ä½ï¼Œå…± %d æª”è‚¡ç¥¨ã€‚", len(ordered_tickers))
    upper_tickers = [t.upper() for t in ordered_tickers]
    from sqlmodel import select as sql_select
    from domain.entities import Stock as StockEntity
    stocks = session.exec(
        sql_select(StockEntity).where(StockEntity.ticker.in_(upper_tickers))
    ).all()
    stock_map = {s.ticker: s for s in stocks}
    for index, ticker in enumerate(upper_tickers):
        s = stock_map.get(ticker)
        if s:
            s.display_order = index
    session.commit()
    return {"message": f"âœ… å·²æ›´æ–° {len(ordered_tickers)} æª”è‚¡ç¥¨çš„é¡¯ç¤ºé †ä½ã€‚"}


def list_removed_stocks(session: Session) -> list[dict]:
    """å–å¾—æ‰€æœ‰å·²ç§»é™¤çš„è‚¡ç¥¨ï¼Œå«æœ€æ–°ç§»é™¤åŸå› ï¼ˆæ‰¹æ¬¡æŸ¥è©¢ï¼Œé¿å… N+1ï¼‰ã€‚"""
    logger.info("å–å¾—å·²ç§»é™¤è‚¡ç¥¨æ¸…å–®...")
    stocks = repo.find_inactive_stocks(session)

    # ä¸€æ¬¡æ€§å–å¾—æ‰€æœ‰å·²ç§»é™¤è‚¡ç¥¨çš„æœ€æ–°ç§»é™¤ç´€éŒ„
    tickers = [s.ticker for s in stocks]
    removal_map = repo.find_latest_removals_batch(session, tickers)

    results: list[dict] = []
    for stock in stocks:
        latest_removal = removal_map.get(stock.ticker)
        results.append({
            "ticker": stock.ticker,
            "category": stock.category,
            "current_thesis": stock.current_thesis,
            "removal_reason": latest_removal.reason if latest_removal else "æœªçŸ¥",
            "removed_at": (
                latest_removal.created_at.isoformat()
                if latest_removal and latest_removal.created_at
                else None
            ),
        })

    logger.info("å…± %d æª”å·²ç§»é™¤è‚¡ç¥¨ã€‚", len(results))
    return results


def get_removal_history(session: Session, ticker: str) -> list[dict]:
    """å–å¾—æŒ‡å®šè‚¡ç¥¨çš„å®Œæ•´ç§»é™¤ç´€éŒ„æ­·å²ã€‚"""
    ticker_upper = ticker.upper()

    stock = repo.find_stock_by_ticker(session, ticker_upper)
    if not stock:
        raise StockNotFoundError(f"æ‰¾ä¸åˆ°è‚¡ç¥¨ {ticker_upper}ã€‚")

    logs = repo.find_removal_history(session, ticker_upper)
    return [
        {
            "reason": log.reason,
            "created_at": log.created_at.isoformat() if log.created_at else None,
        }
        for log in logs
    ]


# ===========================================================================
# Thesis Service
# ===========================================================================


def add_thesis(
    session: Session,
    ticker: str,
    content: str,
    tags: list[str] | None = None,
) -> dict:
    """ç‚ºæŒ‡å®šè‚¡ç¥¨æ–°å¢è§€é»ï¼Œè‡ªå‹•éå¢ç‰ˆæœ¬è™Ÿã€‚"""
    ticker_upper = ticker.upper()
    tags = tags or []
    tags_str = _tags_to_str(tags)
    logger.info("æ›´æ–°è§€é»ï¼š%sï¼ˆæ¨™ç±¤ï¼š%sï¼‰", ticker_upper, tags)

    stock = repo.find_stock_by_ticker(session, ticker_upper)
    if not stock:
        raise StockNotFoundError(f"æ‰¾ä¸åˆ°è‚¡ç¥¨ {ticker_upper}ã€‚")

    max_version = repo.get_max_thesis_version(session, ticker_upper)
    new_version = max_version + 1

    thesis_log = ThesisLog(
        stock_ticker=ticker_upper,
        content=content,
        tags=tags_str,
        version=new_version,
    )
    repo.create_thesis_log(session, thesis_log)

    stock.current_thesis = content
    stock.current_tags = tags_str
    repo.update_stock(session, stock)
    session.commit()

    logger.info("è‚¡ç¥¨ %s è§€é»å·²æ›´æ–°è‡³ç¬¬ %d ç‰ˆã€‚", ticker_upper, new_version)

    return {
        "message": f"âœ… {ticker_upper} è§€é»å·²æ›´æ–°è‡³ç¬¬ {new_version} ç‰ˆã€‚",
        "version": new_version,
        "content": content,
        "tags": tags,
    }


def get_thesis_history(session: Session, ticker: str) -> list[dict]:
    """å–å¾—æŒ‡å®šè‚¡ç¥¨çš„å®Œæ•´è§€é»ç‰ˆæ§æ­·å²ã€‚"""
    ticker_upper = ticker.upper()

    stock = repo.find_stock_by_ticker(session, ticker_upper)
    if not stock:
        raise StockNotFoundError(f"æ‰¾ä¸åˆ°è‚¡ç¥¨ {ticker_upper}ã€‚")

    logs = repo.find_thesis_history(session, ticker_upper)
    return [
        {
            "version": log.version,
            "content": log.content,
            "tags": _str_to_tags(log.tags),
            "created_at": log.created_at.isoformat() if log.created_at else None,
        }
        for log in logs
    ]


# ===========================================================================
# Scan Service
# ===========================================================================


def run_scan(session: Session) -> dict:
    """
    V2 ä¸‰å±¤æ¼æ–—æƒæï¼š
    Layer 1: å¸‚å ´æƒ…ç·’ï¼ˆé¢¨å‘çƒè·Œç ´ 60MA æ¯”ä¾‹ï¼‰
    Layer 2: è­·åŸæ²³è¶¨å‹¢ï¼ˆæ¯›åˆ©ç‡ YoYï¼‰
    Layer 3: æŠ€è¡“é¢è¨Šè™Ÿï¼ˆRSI, Bias, Volume Ratioï¼‰
    Decision Engine ç”¢ç”Ÿæ¯æª”è‚¡ç¥¨çš„ signalï¼Œä¸¦é€é Telegram é€šçŸ¥ã€‚
    """
    logger.info("ä¸‰å±¤æ¼æ–—æƒæå•Ÿå‹•...")

    # === Layer 1: å¸‚å ´æƒ…ç·’ ===
    trend_stocks = repo.find_active_stocks_by_category(session, StockCategory.TREND_SETTER)
    trend_tickers = [s.ticker for s in trend_stocks]
    logger.info("Layer 1 â€” é¢¨å‘çƒè‚¡ç¥¨ï¼š%s", trend_tickers)

    market_sentiment = analyze_market_sentiment(trend_tickers)
    market_status_value = market_sentiment.get("status", "POSITIVE")
    logger.info("Layer 1 â€” å¸‚å ´æƒ…ç·’ï¼š%sï¼ˆ%sï¼‰", market_status_value, market_sentiment.get("details", ""))

    # === Layer 2 & 3: é€è‚¡åˆ†æ + Decision Engineï¼ˆä¸¦è¡Œï¼‰ ===
    all_stocks = repo.find_active_stocks(session)
    stock_map: dict[str, Stock] = {s.ticker: s for s in all_stocks}
    logger.info("æƒæå°è±¡ï¼š%d æª”è‚¡ç¥¨ã€‚", len(all_stocks))

    def _analyze_single_stock(stock: Stock, mkt_status: str) -> dict:
        """å–®ä¸€è‚¡ç¥¨çš„åˆ†æé‚è¼¯ï¼ˆå¯åœ¨ Thread ä¸­åŸ·è¡Œï¼‰ã€‚"""
        ticker = stock.ticker
        alerts: list[str] = []

        if stock.category == StockCategory.ETF:
            moat_result = {"ticker": ticker, "moat": MoatStatus.NOT_AVAILABLE.value, "details": ETF_MOAT_NA_MESSAGE}
        else:
            moat_result = analyze_moat_trend(ticker)
        moat_value = moat_result.get("moat", MoatStatus.NOT_AVAILABLE.value)
        moat_details = moat_result.get("details", "")

        signals = get_technical_signals(ticker)
        rsi: float | None = None
        bias: float | None = None
        volume_ratio: float | None = None
        price: float | None = None

        if signals and "error" not in signals:
            rsi = signals.get("rsi")
            bias = signals.get("bias")
            volume_ratio = signals.get("volume_ratio")
            price = signals.get("price")
        elif signals and "error" in signals:
            alerts.append(signals["error"])

        signal = determine_scan_signal(moat_value, mkt_status, rsi, bias)

        if signal == ScanSignal.THESIS_BROKEN:
            alerts.append(f"ğŸ”´ {ticker} è­·åŸæ²³é¬†å‹•ï¼{moat_details}")
        elif signal == ScanSignal.CONTRARIAN_BUY:
            alerts.append(f"ğŸŸ¢ {ticker} é€†å‹¢è²·å…¥è¨Šè™Ÿï¼ˆRSI={rsi}ï¼Œå¸‚å ´æ­£é¢ï¼‰")
        elif signal == ScanSignal.OVERHEATED:
            alerts.append(f"ğŸŸ  {ticker} ä¹–é›¢ç‡éç†±ï¼ˆBias={bias}%ï¼‰")

        if moat_value == MoatStatus.STABLE.value and moat_details:
            alerts.append(f"ğŸŸ¢ {ticker} {moat_details}")
        if moat_value == MoatStatus.NOT_AVAILABLE.value and moat_details:
            alerts.append(f"âš ï¸ {ticker} {moat_details}")

        logger.info(
            "%s â†’ signal=%s, moat=%s, rsi=%s, bias=%s, vol_ratio=%s",
            ticker, signal.value, moat_value, rsi, bias, volume_ratio,
        )

        return {
            "ticker": ticker,
            "category": stock.category,
            "signal": signal.value,
            "alerts": alerts,
            "moat": moat_value,
            "bias": bias,
            "volume_ratio": volume_ratio,
            "price": price,
            "rsi": rsi,
            "market_status": market_status_value,
        }

    results: list[dict] = []
    with ThreadPoolExecutor(max_workers=SCAN_THREAD_POOL_SIZE) as executor:
        futures = {
            executor.submit(_analyze_single_stock, s, market_status_value): s
            for s in all_stocks
        }
        for future in as_completed(futures):
            try:
                results.append(future.result())
            except Exception as exc:
                stock = futures[future]
                logger.error("æƒæ %s å¤±æ•—ï¼š%s", stock.ticker, exc, exc_info=True)

    # === æŒä¹…åŒ–æƒæç´€éŒ„ ===
    for r in results:
        scan_log = ScanLog(
            stock_ticker=r["ticker"],
            signal=r["signal"],
            market_status=market_status_value,
            details=json.dumps(r["alerts"], ensure_ascii=False),
        )
        repo.create_scan_log(session, scan_log)
    session.commit()

    # === æª¢æŸ¥è‡ªè¨‚åƒ¹æ ¼è­¦å ± ===
    _check_price_alerts(session, results)

    # === å·®ç•°æ¯”å° + é€šçŸ¥ ===
    category_icon = {
        "Trend_Setter": "ğŸŒŠ",
        "Moat": "ğŸ°",
        "Growth": "ğŸš€",
        "ETF": "ğŸ§º",
    }

    # æ¯”å°æ¯æª”è‚¡ç¥¨çš„ current signal vs last_scan_signal
    new_or_changed: list[dict] = []  # signal å¾ NORMALâ†’é NORMALï¼Œæˆ–é NORMAL é¡å‹æ”¹è®Š
    resolved: list[dict] = []        # signal å¾é NORMALâ†’NORMAL
    signal_updates: dict[str, str] = {}

    for r in results:
        ticker = r["ticker"]
        current_signal = r["signal"]
        stock_obj = stock_map.get(ticker)
        prev_signal = stock_obj.last_scan_signal if stock_obj else ScanSignal.NORMAL.value

        signal_updates[ticker] = current_signal

        if current_signal == prev_signal:
            continue  # ç„¡è®ŠåŒ–ï¼Œä¸é€šçŸ¥
        if current_signal != ScanSignal.NORMAL.value:
            new_or_changed.append(r)
        else:
            resolved.append(r)

    # æŒä¹…åŒ–æ‰€æœ‰è‚¡ç¥¨çš„æœ€æ–° signalï¼ˆä¸è«–æ˜¯å¦æœ‰è®ŠåŒ–ï¼‰
    repo.bulk_update_scan_signals(session, signal_updates)

    has_changes = bool(new_or_changed) or bool(resolved)

    if has_changes:
        logger.warning(
            "æƒæå·®ç•°ï¼š%d æª”æ–°å¢/è®Šæ›´ï¼Œ%d æª”å·²æ¢å¾©ã€‚",
            len(new_or_changed), len(resolved),
        )
        header = f"ğŸ”” <b>Azusa Radar V2 æƒæï¼ˆå·®ç•°é€šçŸ¥ï¼‰</b>\nå¸‚å ´æƒ…ç·’ï¼š{market_status_value}\n"

        # æ–°å¢/æƒ¡åŒ–çš„è‚¡ç¥¨ä¾é¡åˆ¥åˆ†çµ„
        body_parts: list[str] = []
        if new_or_changed:
            grouped: dict[str, list[str]] = {}
            for r in new_or_changed:
                cat = r.get("category", "Growth")
                cat_value = cat.value if hasattr(cat, "value") else str(cat)
                grouped.setdefault(cat_value, []).extend(r["alerts"])

            for cat_key in ["Trend_Setter", "Moat", "Growth", "ETF"]:
                if cat_key in grouped:
                    icon = category_icon.get(cat_key, "")
                    label = CATEGORY_LABEL.get(cat_key, cat_key)
                    section_header = f"\n{icon} <b>{label}</b>"
                    section_lines = "\n".join(grouped[cat_key])
                    body_parts.append(f"{section_header}\n{section_lines}")

        # æ¢å¾©æ­£å¸¸çš„è‚¡ç¥¨
        if resolved:
            resolved_tickers = ", ".join(r["ticker"] for r in resolved)
            body_parts.append(f"\nâœ… <b>å·²æ¢å¾©æ­£å¸¸</b>\n{resolved_tickers}")

        send_telegram_message(header + "\n".join(body_parts))
    else:
        logger.info("æƒæå®Œæˆï¼Œè¨Šè™Ÿç„¡è®ŠåŒ–ï¼Œè·³éé€šçŸ¥ã€‚")

    return {"market_status": market_sentiment, "results": results}


def _check_price_alerts(session: Session, results: list[dict]) -> None:
    """æª¢æŸ¥æ‰€æœ‰å•Ÿç”¨ä¸­çš„è‡ªè¨‚åƒ¹æ ¼è­¦å ±ï¼Œè§¸ç™¼æ™‚ç™¼é€ Telegram é€šçŸ¥ã€‚"""
    all_alerts = repo.find_all_active_alerts(session)
    if not all_alerts:
        return

    # å»ºç«‹ ticker â†’ result å¿«æŸ¥è¡¨
    result_map = {r["ticker"]: r for r in results}
    triggered_msgs: list[str] = []
    now = datetime.now(timezone.utc)

    for alert in all_alerts:
        r = result_map.get(alert.stock_ticker)
        if not r:
            continue

        # å–å¾—æŒ‡æ¨™å€¼
        metric_value: float | None = None
        if alert.metric == "rsi":
            metric_value = r.get("rsi")
        elif alert.metric == "price":
            metric_value = r.get("price")
        elif alert.metric == "bias":
            metric_value = r.get("bias")

        if metric_value is None:
            continue

        # æ¯”è¼ƒ
        triggered = False
        if alert.operator == "lt" and metric_value < alert.threshold:
            triggered = True
        elif alert.operator == "gt" and metric_value > alert.threshold:
            triggered = True

        if not triggered:
            continue

        # å†·å»æª¢æŸ¥
        if alert.last_triggered_at:
            cooldown = timedelta(hours=PRICE_ALERT_COOLDOWN_HOURS)
            if now - alert.last_triggered_at < cooldown:
                continue

        # è§¸ç™¼
        alert.last_triggered_at = now
        session.add(alert)
        op_label = "<" if alert.operator == "lt" else ">"
        triggered_msgs.append(
            f"ğŸ”” {alert.stock_ticker} {alert.metric}={metric_value} "
            f"{op_label} {alert.threshold}"
        )

    if triggered_msgs:
        session.commit()
        msg = "âš¡ <b>è‡ªè¨‚åƒ¹æ ¼è­¦å ±è§¸ç™¼</b>\n\n" + "\n".join(triggered_msgs)
        send_telegram_message(msg)
        logger.warning("è§¸ç™¼ %d å€‹è‡ªè¨‚åƒ¹æ ¼è­¦å ±ã€‚", len(triggered_msgs))


# ===========================================================================
# Scan History Service
# ===========================================================================


def get_scan_history(session: Session, ticker: str, limit: int = SCAN_HISTORY_DEFAULT_LIMIT) -> list[dict]:
    """å–å¾—æŒ‡å®šè‚¡ç¥¨çš„æƒææ­·å²ã€‚"""
    ticker_upper = ticker.upper()
    stock = repo.find_stock_by_ticker(session, ticker_upper)
    if not stock:
        raise StockNotFoundError(f"æ‰¾ä¸åˆ°è‚¡ç¥¨ {ticker_upper}ã€‚")

    logs = repo.find_scan_history(session, ticker_upper, limit)
    return [
        {
            "signal": log.signal,
            "market_status": log.market_status,
            "details": log.details,
            "scanned_at": log.scanned_at.isoformat() if log.scanned_at else None,
        }
        for log in logs
    ]


def get_latest_scan_logs(session: Session, limit: int = 50) -> list[dict]:
    """å–å¾—æœ€è¿‘çš„æƒæç´€éŒ„ã€‚"""
    logs = repo.find_latest_scan_logs(session, limit)
    return [
        {
            "ticker": log.stock_ticker,
            "signal": log.signal,
            "market_status": log.market_status,
            "details": log.details,
            "scanned_at": log.scanned_at.isoformat() if log.scanned_at else None,
        }
        for log in logs
    ]


# ===========================================================================
# Price Alert Service
# ===========================================================================


def create_price_alert(
    session: Session,
    ticker: str,
    metric: str,
    operator: str,
    threshold: float,
) -> dict:
    """å»ºç«‹è‡ªè¨‚åƒ¹æ ¼è­¦å ±ã€‚"""
    ticker_upper = ticker.upper()
    stock = repo.find_stock_by_ticker(session, ticker_upper)
    if not stock:
        raise StockNotFoundError(f"æ‰¾ä¸åˆ°è‚¡ç¥¨ {ticker_upper}ã€‚")

    alert = PriceAlert(
        stock_ticker=ticker_upper,
        metric=metric,
        operator=operator,
        threshold=threshold,
    )
    saved = repo.create_price_alert(session, alert)
    op_label = "<" if operator == "lt" else ">"
    return {
        "message": f"âœ… å·²å»ºç«‹è­¦å ±ï¼š{ticker_upper} {metric} {op_label} {threshold}",
        "id": saved.id,
    }


def list_price_alerts(session: Session, ticker: str) -> list[dict]:
    """å–å¾—æŒ‡å®šè‚¡ç¥¨çš„æ‰€æœ‰è­¦å ±ã€‚"""
    alerts = repo.find_all_alerts_for_stock(session, ticker.upper())
    return [
        {
            "id": a.id,
            "metric": a.metric,
            "operator": a.operator,
            "threshold": a.threshold,
            "is_active": a.is_active,
            "last_triggered_at": (
                a.last_triggered_at.isoformat() if a.last_triggered_at else None
            ),
        }
        for a in alerts
    ]


def delete_price_alert(session: Session, alert_id: int) -> dict:
    """åˆªé™¤åƒ¹æ ¼è­¦å ±ã€‚"""
    alert = repo.find_price_alert_by_id(session, alert_id)
    if not alert:
        return {"message": "âš ï¸ æ‰¾ä¸åˆ°æ­¤è­¦å ±ã€‚"}
    repo.delete_price_alert(session, alert)
    return {"message": "âœ… è­¦å ±å·²åˆªé™¤ã€‚"}


# ===========================================================================
# Weekly Digest Service
# ===========================================================================


def send_weekly_digest(session: Session) -> dict:
    """
    ç™¼é€æ¯é€± Telegram æ‘˜è¦ï¼š
    - ç›®å‰æ‰€æœ‰é NORMAL è‚¡ç¥¨
    - éå» 7 å¤©è¨Šè™Ÿè®ŠåŒ–
    - æŠ•è³‡çµ„åˆå¥åº·åˆ†æ•¸
    """
    logger.info("é–‹å§‹ç”Ÿæˆæ¯é€±æ‘˜è¦...")

    all_stocks = repo.find_active_stocks(session)
    total = len(all_stocks)
    if total == 0:
        send_telegram_message("ğŸ“Š <b>Azusa Radar æ¯é€±æ‘˜è¦</b>\n\nç›®å‰ç„¡è¿½è¹¤è‚¡ç¥¨ã€‚")
        return {"message": "ç„¡è¿½è¹¤è‚¡ç¥¨ã€‚"}

    # ç›®å‰é NORMAL è‚¡ç¥¨
    non_normal = [s for s in all_stocks if s.last_scan_signal != "NORMAL"]
    normal_count = total - len(non_normal)
    health_score = round(normal_count / total * 100, 1)

    # éå» 7 å¤©çš„è¨Šè™Ÿè®ŠåŒ–
    seven_days_ago = datetime.now(timezone.utc) - timedelta(days=WEEKLY_DIGEST_LOOKBACK_DAYS)
    recent_logs = repo.find_scan_logs_since(session, seven_days_ago)

    # çµ±è¨ˆæ¯æª”è‚¡ç¥¨çš„è¨Šè™Ÿè®ŠåŒ–æ¬¡æ•¸
    signal_changes: dict[str, int] = {}
    prev_signals: dict[str, str] = {}
    # æŒ‰æ™‚é–“æ­£åºè™•ç†ï¼ˆæœ€èˆŠâ†’æœ€æ–°ï¼‰
    for log in reversed(recent_logs):
        tk = log.stock_ticker
        if tk in prev_signals and prev_signals[tk] != log.signal:
            signal_changes[tk] = signal_changes.get(tk, 0) + 1
        prev_signals[tk] = log.signal

    # çµ„åˆè¨Šæ¯
    parts: list[str] = [
        f"ğŸ“Š <b>Azusa Radar æ¯é€±æ‘˜è¦</b>\n",
        f"ğŸ¥ æŠ•è³‡çµ„åˆå¥åº·åˆ†æ•¸ï¼š<b>{health_score}%</b>ï¼ˆ{normal_count}/{total} æ­£å¸¸ï¼‰\n",
    ]

    if non_normal:
        parts.append("âš ï¸ <b>ç›®å‰ç•°å¸¸è‚¡ç¥¨ï¼š</b>")
        for s in non_normal:
            cat_label = CATEGORY_LABEL.get(s.category.value, s.category.value)
            parts.append(f"  â€¢ {s.ticker}ï¼ˆ{cat_label}ï¼‰â†’ {s.last_scan_signal}")

    if signal_changes:
        parts.append("\nğŸ”„ <b>æœ¬é€±è¨Šè™Ÿè®ŠåŒ–ï¼š</b>")
        for tk, count in sorted(signal_changes.items(), key=lambda x: -x[1]):
            parts.append(f"  â€¢ {tk}ï¼šè®ŠåŒ– {count} æ¬¡")

    if not non_normal and not signal_changes:
        parts.append("âœ… ä¸€åˆ‡æ­£å¸¸ï¼Œæœ¬é€±ç„¡ç•°å¸¸è¨Šè™Ÿã€‚")

    message = "\n".join(parts)
    send_telegram_message(message)
    logger.info("æ¯é€±æ‘˜è¦å·²ç™¼é€ã€‚")

    return {"message": "æ¯é€±æ‘˜è¦å·²ç™¼é€ã€‚", "health_score": health_score}


# ===========================================================================
# Portfolio Summary Service (for OpenClaw / chat)
# ===========================================================================


def get_portfolio_summary(session: Session) -> str:
    """
    ç”¢ç”Ÿç´”æ–‡å­—æŠ•è³‡çµ„åˆæ‘˜è¦ï¼Œå°ˆç‚º chat / AI agent è¨­è¨ˆã€‚
    """
    stocks = repo.find_active_stocks(session)
    if not stocks:
        return "Azusa Radar â€” ç›®å‰ç„¡è¿½è¹¤è‚¡ç¥¨ã€‚"

    non_normal = [s for s in stocks if s.last_scan_signal != "NORMAL"]
    health = round((len(stocks) - len(non_normal)) / len(stocks) * 100, 1)

    lines: list[str] = [f"Azusa Radar â€” Health: {health}%", ""]

    for cat in ["Trend_Setter", "Moat", "Growth", "ETF"]:
        group = [s for s in stocks if s.category.value == cat]
        if group:
            label = CATEGORY_LABEL.get(cat, cat)
            lines.append(f"[{label}] {', '.join(s.ticker for s in group)}")

    if non_normal:
        lines += ["", "Abnormal:"]
        for s in non_normal:
            lines.append(f"  {s.ticker} -> {s.last_scan_signal}")
    else:
        lines += ["", "All signals normal."]

    return "\n".join(lines)


# ===========================================================================
# Import Service
# ===========================================================================


def import_stocks(session: Session, stock_list: list[dict]) -> dict:
    """
    æ‰¹æ¬¡åŒ¯å…¥è‚¡ç¥¨ï¼ˆupsert é‚è¼¯ï¼‰ã€‚
    æ–°è‚¡ç¥¨å»ºç«‹ï¼Œå·²å­˜åœ¨çš„æ›´æ–°è§€é»èˆ‡æ¨™ç±¤ã€‚
    """
    logger.info("æ‰¹æ¬¡åŒ¯å…¥ %d ç­†è‚¡ç¥¨...", len(stock_list))
    created = 0
    updated = 0
    errors: list[str] = []

    for item in stock_list:
        ticker = item.get("ticker", "").strip().upper()
        category_str = item.get("category", "Growth")
        thesis = item.get("thesis", "") or item.get("initial_thesis", "")
        tags = item.get("tags", [])

        if not ticker:
            errors.append("ç¼ºå°‘ ticker æ¬„ä½")
            continue

        try:
            category = StockCategory(category_str)
        except ValueError:
            errors.append(f"{ticker}: ç„¡æ•ˆåˆ†é¡ {category_str}")
            continue

        existing = repo.find_stock_by_ticker(session, ticker)
        tags_str = _tags_to_str(tags)

        if existing:
            # Upsert: æ›´æ–°è§€é»èˆ‡æ¨™ç±¤
            if thesis:
                max_version = repo.get_max_thesis_version(session, ticker)
                thesis_log = ThesisLog(
                    stock_ticker=ticker,
                    content=thesis,
                    tags=tags_str,
                    version=max_version + 1,
                )
                repo.create_thesis_log(session, thesis_log)
                existing.current_thesis = thesis
            if tags:
                existing.current_tags = tags_str
            existing.category = category
            repo.update_stock(session, existing)
            updated += 1
        else:
            # æ–°å¢
            stock = Stock(
                ticker=ticker,
                category=category,
                current_thesis=thesis,
                current_tags=tags_str,
                is_active=True,
            )
            session.add(stock)
            thesis_log = ThesisLog(
                stock_ticker=ticker,
                content=thesis,
                tags=tags_str,
                version=1,
            )
            repo.create_thesis_log(session, thesis_log)
            created += 1

    session.commit()
    logger.info("åŒ¯å…¥å®Œæˆï¼šæ–°å¢ %dï¼Œæ›´æ–° %dï¼ŒéŒ¯èª¤ %dã€‚", created, updated, len(errors))

    return {
        "message": f"âœ… åŒ¯å…¥å®Œæˆï¼šæ–°å¢ {created}ï¼Œæ›´æ–° {updated}ï¼ŒéŒ¯èª¤ {len(errors)}ã€‚",
        "created": created,
        "updated": updated,
        "errors": errors,
    }
