"""
Application â€” Service Layer (Use Cases)ã€‚
ç·¨æ’æ¥­å‹™æµç¨‹ï¼Œå”èª¿ Repository èˆ‡ Infrastructure Adapterã€‚
ä¸åŒ…å« HTTP/æ¡†æ¶é‚è¼¯ã€‚
"""

import json
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta, timezone

from sqlmodel import Session, select

from domain.analysis import determine_scan_signal
from domain.constants import (
    CATEGORY_DISPLAY_ORDER,
    CATEGORY_ICON,
    DEFAULT_IMPORT_CATEGORY,
    DEFAULT_USER_ID,
    DEFAULT_WEBHOOK_THESIS,
    FX_HIGH_CONCENTRATION_PCT,
    FX_MEDIUM_CONCENTRATION_PCT,
    FX_SIGNIFICANT_CHANGE_PCT,
    LATEST_SCAN_LOGS_DEFAULT_LIMIT,
    PRICE_ALERT_COOLDOWN_HOURS,
    REMOVAL_REASON_UNKNOWN,
    SCAN_HISTORY_DEFAULT_LIMIT,
    SCAN_THREAD_POOL_SIZE,
    SKIP_MOAT_CATEGORIES,
    SKIP_SIGNALS_CATEGORIES,
    WEBHOOK_ACTION_REGISTRY,
    WEBHOOK_MISSING_TICKER,
    WEEKLY_DIGEST_LOOKBACK_DAYS,
    XRAY_SINGLE_STOCK_WARN_PCT,
    XRAY_SKIP_CATEGORIES,
)
from domain.entities import PriceAlert, RemovalLog, ScanLog, Stock, ThesisLog
from domain.enums import CATEGORY_LABEL, MarketSentiment, MoatStatus, ScanSignal, StockCategory
from infrastructure import repositories as repo
from infrastructure.market_data import (
    analyze_market_sentiment,
    analyze_moat_trend,
    get_etf_top_holdings,
    get_exchange_rates,
    get_forex_history,
    get_technical_signals,
)
from infrastructure.notification import send_telegram_message_dual
from logging_config import get_logger

logger = get_logger(__name__)


# ---------------------------------------------------------------------------
# Tag è½‰æ›å·¥å…·
# ---------------------------------------------------------------------------


def _tags_to_str(tags: list[str]) -> str:
    """å°‡æ¨™ç±¤åˆ—è¡¨è½‰ç‚ºé€—è™Ÿåˆ†éš”å­—ä¸²å­˜å…¥ DBã€‚"""
    return ",".join(t.strip() for t in tags if t.strip())


def _str_to_tags(s: str) -> list[str]:
    """å°‡ DB ä¸­çš„é€—è™Ÿåˆ†éš”å­—ä¸²è½‰ç‚ºæ¨™ç±¤åˆ—è¡¨ã€‚"""
    return [t.strip() for t in s.split(",") if t.strip()] if s else []


# ===========================================================================
# Stock Service
# ===========================================================================


class StockNotFoundError(Exception):
    """è‚¡ç¥¨ä¸å­˜åœ¨ã€‚"""


class StockAlreadyExistsError(Exception):
    """è‚¡ç¥¨å·²å­˜åœ¨ã€‚"""


class StockAlreadyInactiveError(Exception):
    """è‚¡ç¥¨å·²æ˜¯åœç”¨ç‹€æ…‹ã€‚"""


class StockAlreadyActiveError(Exception):
    """è‚¡ç¥¨å·²æ˜¯å•Ÿç”¨ç‹€æ…‹ã€‚"""


class CategoryUnchangedError(Exception):
    """åˆ†é¡ç›¸åŒï¼Œç„¡éœ€è®Šæ›´ã€‚"""


# ---------------------------------------------------------------------------
# å…±ç”¨å…§éƒ¨å·¥å…·
# ---------------------------------------------------------------------------


def _get_stock_or_raise(session: Session, ticker: str) -> Stock:
    """æŸ¥è©¢è‚¡ç¥¨ï¼Œä¸å­˜åœ¨æ™‚æ‹‹å‡º StockNotFoundErrorã€‚"""
    upper = ticker.upper()
    stock = repo.find_stock_by_ticker(session, upper)
    if not stock:
        raise StockNotFoundError(f"æ‰¾ä¸åˆ°è‚¡ç¥¨ {upper}ã€‚")
    return stock


def _append_thesis_log(
    session: Session,
    ticker: str,
    content: str,
    tags: str = "",
) -> ThesisLog:
    """å»ºç«‹æ–°ç‰ˆè§€é»ç´€éŒ„ï¼ˆè‡ªå‹•éå¢ç‰ˆæœ¬è™Ÿï¼‰ã€‚"""
    max_version = repo.get_max_thesis_version(session, ticker)
    log = ThesisLog(
        stock_ticker=ticker,
        content=content,
        tags=tags,
        version=max_version + 1,
    )
    repo.create_thesis_log(session, log)
    return log


def create_stock(
    session: Session,
    ticker: str,
    category: StockCategory,
    thesis: str,
    tags: list[str] | None = None,
) -> Stock:
    """
    æ–°å¢è‚¡ç¥¨åˆ°è¿½è¹¤æ¸…å–®ï¼ŒåŒæ™‚å»ºç«‹ç¬¬ä¸€ç­†è§€é»ç´€éŒ„ã€‚
    """
    ticker_upper = ticker.upper()
    tags = tags or []
    tags_str = _tags_to_str(tags)
    logger.info("æ–°å¢è‚¡ç¥¨ï¼š%sï¼ˆåˆ†é¡ï¼š%sï¼Œæ¨™ç±¤ï¼š%sï¼‰", ticker_upper, category.value, tags)

    existing = repo.find_stock_by_ticker(session, ticker_upper)
    if existing:
        raise StockAlreadyExistsError(f"è‚¡ç¥¨ {ticker_upper} å·²å­˜åœ¨è¿½è¹¤æ¸…å–®ä¸­ã€‚")

    stock = Stock(
        ticker=ticker_upper,
        category=category,
        current_thesis=thesis,
        current_tags=tags_str,
        is_active=True,
    )
    session.add(stock)

    thesis_log = ThesisLog(
        stock_ticker=ticker_upper,
        content=thesis,
        tags=tags_str,
        version=1,
    )
    repo.create_thesis_log(session, thesis_log)

    session.commit()
    session.refresh(stock)

    logger.info("è‚¡ç¥¨ %s å·²æˆåŠŸæ–°å¢è‡³è¿½è¹¤æ¸…å–®ã€‚", ticker_upper)
    return stock


def list_active_stocks(session: Session) -> list[dict]:
    """å–å¾—æ‰€æœ‰å•Ÿç”¨ä¸­çš„è¿½è¹¤è‚¡ç¥¨ï¼ˆåƒ… DB è³‡æ–™ï¼Œä¸å«æŠ€è¡“è¨Šè™Ÿï¼‰ã€‚"""
    logger.info("å–å¾—æ‰€æœ‰è¿½è¹¤è‚¡ç¥¨æ¸…å–®...")
    stocks = repo.find_active_stocks(session)
    logger.info("å…± %d æª”è¿½è¹¤ä¸­è‚¡ç¥¨ã€‚", len(stocks))

    return [
        {
            "ticker": stock.ticker,
            "category": stock.category,
            "current_thesis": stock.current_thesis,
            "current_tags": _str_to_tags(stock.current_tags),
            "display_order": stock.display_order,
            "is_active": stock.is_active,
        }
        for stock in stocks
    ]


def update_stock_category(session: Session, ticker: str, new_category: StockCategory) -> dict:
    """
    åˆ‡æ›è‚¡ç¥¨åˆ†é¡ï¼Œä¸¦åœ¨è§€é»æ­·å²ä¸­è¨˜éŒ„è®Šæ›´ã€‚
    """
    stock = _get_stock_or_raise(session, ticker)
    ticker_upper = stock.ticker
    logger.info("åˆ†é¡è®Šæ›´è«‹æ±‚ï¼š%s â†’ %s", ticker_upper, new_category.value)

    old_category = stock.category
    if old_category == new_category:
        old_label = CATEGORY_LABEL.get(old_category.value, old_category.value)
        raise CategoryUnchangedError(f"è‚¡ç¥¨ {ticker_upper} å·²ç¶“æ˜¯ {old_label} åˆ†é¡ã€‚")

    stock.category = new_category
    repo.update_stock(session, stock)

    old_label = CATEGORY_LABEL.get(old_category.value, old_category.value)
    new_label = CATEGORY_LABEL.get(new_category.value, new_category.value)
    _append_thesis_log(session, ticker_upper, f"[åˆ†é¡è®Šæ›´] {old_label} â†’ {new_label}")

    session.commit()
    logger.info("è‚¡ç¥¨ %s åˆ†é¡å·²å¾ %s è®Šæ›´ç‚º %sã€‚", ticker_upper, old_label, new_label)

    return {
        "message": f"âœ… {ticker_upper} åˆ†é¡å·²å¾ã€Œ{old_label}ã€è®Šæ›´ç‚ºã€Œ{new_label}ã€ã€‚",
        "old_category": old_category.value,
        "new_category": new_category.value,
    }


def deactivate_stock(session: Session, ticker: str, reason: str) -> dict:
    """
    ç§»é™¤è¿½è¹¤è‚¡ç¥¨ï¼Œè¨˜éŒ„ç§»é™¤åŸå› èˆ‡è§€é»ç‰ˆæ§ã€‚
    """
    stock = _get_stock_or_raise(session, ticker)
    ticker_upper = stock.ticker
    logger.info("ç§»é™¤è¿½è¹¤ï¼š%s", ticker_upper)

    if not stock.is_active:
        raise StockAlreadyInactiveError(f"è‚¡ç¥¨ {ticker_upper} å·²ç¶“æ˜¯ç§»é™¤ç‹€æ…‹ã€‚")

    stock.is_active = False
    repo.update_stock(session, stock)

    removal_log = RemovalLog(stock_ticker=ticker_upper, reason=reason)
    repo.create_removal_log(session, removal_log)

    _append_thesis_log(session, ticker_upper, f"[å·²ç§»é™¤] {reason}")

    session.commit()
    logger.info("è‚¡ç¥¨ %s å·²ç§»é™¤è¿½è¹¤ï¼ˆåŸå› ï¼š%sï¼‰ã€‚", ticker_upper, reason)

    return {"message": f"âœ… {ticker_upper} å·²å¾è¿½è¹¤æ¸…å–®ç§»é™¤ã€‚", "reason": reason}


def reactivate_stock(
    session: Session,
    ticker: str,
    category: StockCategory | None = None,
    thesis: str | None = None,
) -> dict:
    """
    é‡æ–°å•Ÿç”¨å·²ç§»é™¤çš„è‚¡ç¥¨ã€‚å¯é¸æ“‡æ€§æ›´æ–°åˆ†é¡èˆ‡è§€é»ã€‚
    """
    stock = _get_stock_or_raise(session, ticker)
    ticker_upper = stock.ticker
    logger.info("é‡æ–°å•Ÿç”¨è¿½è¹¤ï¼š%s", ticker_upper)

    if stock.is_active:
        raise StockAlreadyActiveError(f"è‚¡ç¥¨ {ticker_upper} å·²ç¶“æ˜¯å•Ÿç”¨ç‹€æ…‹ã€‚")

    stock.is_active = True
    stock.last_scan_signal = ScanSignal.NORMAL.value
    if category:
        stock.category = category
    repo.update_stock(session, stock)

    _append_thesis_log(session, ticker_upper, thesis or "[é‡æ–°å•Ÿç”¨è¿½è¹¤]")

    if thesis:
        stock.current_thesis = thesis
        repo.update_stock(session, stock)

    session.commit()
    logger.info("è‚¡ç¥¨ %s å·²é‡æ–°å•Ÿç”¨è¿½è¹¤ã€‚", ticker_upper)

    return {"message": f"âœ… {ticker_upper} å·²é‡æ–°å•Ÿç”¨è¿½è¹¤ã€‚"}


def export_stocks(session: Session) -> list[dict]:
    """åŒ¯å‡ºæ‰€æœ‰å•Ÿç”¨ä¸­è‚¡ç¥¨ï¼ˆç²¾ç°¡æ ¼å¼ï¼Œé©ç”¨æ–¼ JSON ä¸‹è¼‰èˆ‡åŒ¯å…¥ï¼‰ã€‚"""
    logger.info("åŒ¯å‡ºæ‰€æœ‰è¿½è¹¤è‚¡ç¥¨...")
    stocks = repo.find_active_stocks(session)
    return [
        {
            "ticker": stock.ticker,
            "category": stock.category.value,
            "thesis": stock.current_thesis,
            "tags": _str_to_tags(stock.current_tags),
        }
        for stock in stocks
    ]


def update_display_order(session: Session, ordered_tickers: list[str]) -> dict:
    """æ‰¹æ¬¡æ›´æ–°è‚¡ç¥¨é¡¯ç¤ºé †ä½ï¼ˆå§”è¨— Repository åŸ·è¡Œï¼‰ã€‚"""
    logger.info("æ›´æ–°é¡¯ç¤ºé †ä½ï¼Œå…± %d æª”è‚¡ç¥¨ã€‚", len(ordered_tickers))
    upper_tickers = [t.upper() for t in ordered_tickers]
    repo.bulk_update_display_order(session, upper_tickers)
    return {"message": f"âœ… å·²æ›´æ–° {len(ordered_tickers)} æª”è‚¡ç¥¨çš„é¡¯ç¤ºé †ä½ã€‚"}


def list_removed_stocks(session: Session) -> list[dict]:
    """å–å¾—æ‰€æœ‰å·²ç§»é™¤çš„è‚¡ç¥¨ï¼Œå«æœ€æ–°ç§»é™¤åŸå› ï¼ˆæ‰¹æ¬¡æŸ¥è©¢ï¼Œé¿å… N+1ï¼‰ã€‚"""
    logger.info("å–å¾—å·²ç§»é™¤è‚¡ç¥¨æ¸…å–®...")
    stocks = repo.find_inactive_stocks(session)

    # ä¸€æ¬¡æ€§å–å¾—æ‰€æœ‰å·²ç§»é™¤è‚¡ç¥¨çš„æœ€æ–°ç§»é™¤ç´€éŒ„
    tickers = [s.ticker for s in stocks]
    removal_map = repo.find_latest_removals_batch(session, tickers)

    results: list[dict] = []
    for stock in stocks:
        latest_removal = removal_map.get(stock.ticker)
        results.append({
            "ticker": stock.ticker,
            "category": stock.category,
            "current_thesis": stock.current_thesis,
            "removal_reason": latest_removal.reason if latest_removal else REMOVAL_REASON_UNKNOWN,
            "removed_at": (
                latest_removal.created_at.isoformat()
                if latest_removal and latest_removal.created_at
                else None
            ),
        })

    logger.info("å…± %d æª”å·²ç§»é™¤è‚¡ç¥¨ã€‚", len(results))
    return results


def get_removal_history(session: Session, ticker: str) -> list[dict]:
    """å–å¾—æŒ‡å®šè‚¡ç¥¨çš„å®Œæ•´ç§»é™¤ç´€éŒ„æ­·å²ã€‚"""
    stock = _get_stock_or_raise(session, ticker)
    logs = repo.find_removal_history(session, stock.ticker)
    return [
        {
            "reason": log.reason,
            "created_at": log.created_at.isoformat() if log.created_at else None,
        }
        for log in logs
    ]


# ===========================================================================
# Thesis Service
# ===========================================================================


def add_thesis(
    session: Session,
    ticker: str,
    content: str,
    tags: list[str] | None = None,
) -> dict:
    """ç‚ºæŒ‡å®šè‚¡ç¥¨æ–°å¢è§€é»ï¼Œè‡ªå‹•éå¢ç‰ˆæœ¬è™Ÿã€‚"""
    stock = _get_stock_or_raise(session, ticker)
    ticker_upper = stock.ticker
    tags = tags or []
    tags_str = _tags_to_str(tags)
    logger.info("æ›´æ–°è§€é»ï¼š%sï¼ˆæ¨™ç±¤ï¼š%sï¼‰", ticker_upper, tags)

    thesis_log = _append_thesis_log(session, ticker_upper, content, tags_str)
    new_version = thesis_log.version

    stock.current_thesis = content
    stock.current_tags = tags_str
    repo.update_stock(session, stock)
    session.commit()

    logger.info("è‚¡ç¥¨ %s è§€é»å·²æ›´æ–°è‡³ç¬¬ %d ç‰ˆã€‚", ticker_upper, new_version)

    return {
        "message": f"âœ… {ticker_upper} è§€é»å·²æ›´æ–°è‡³ç¬¬ {new_version} ç‰ˆã€‚",
        "version": new_version,
        "content": content,
        "tags": tags,
    }


def get_thesis_history(session: Session, ticker: str) -> list[dict]:
    """å–å¾—æŒ‡å®šè‚¡ç¥¨çš„å®Œæ•´è§€é»ç‰ˆæ§æ­·å²ã€‚"""
    stock = _get_stock_or_raise(session, ticker)
    logs = repo.find_thesis_history(session, stock.ticker)
    return [
        {
            "version": log.version,
            "content": log.content,
            "tags": _str_to_tags(log.tags),
            "created_at": log.created_at.isoformat() if log.created_at else None,
        }
        for log in logs
    ]


# ===========================================================================
# Scan Service
# ===========================================================================


def run_scan(session: Session) -> dict:
    """
    V2 ä¸‰å±¤æ¼æ–—æƒæï¼š
    Layer 1: å¸‚å ´æƒ…ç·’ï¼ˆé¢¨å‘çƒè·Œç ´ 60MA æ¯”ä¾‹ï¼‰
    Layer 2: è­·åŸæ²³è¶¨å‹¢ï¼ˆæ¯›åˆ©ç‡ YoYï¼‰
    Layer 3: æŠ€è¡“é¢è¨Šè™Ÿï¼ˆRSI, Bias, Volume Ratioï¼‰
    Decision Engine ç”¢ç”Ÿæ¯æª”è‚¡ç¥¨çš„ signalï¼Œä¸¦é€é Telegram é€šçŸ¥ã€‚
    """
    logger.info("ä¸‰å±¤æ¼æ–—æƒæå•Ÿå‹•...")

    # === Layer 1: å¸‚å ´æƒ…ç·’ ===
    trend_stocks = repo.find_active_stocks_by_category(session, StockCategory.TREND_SETTER)
    trend_tickers = [s.ticker for s in trend_stocks]
    logger.info("Layer 1 â€” é¢¨å‘çƒè‚¡ç¥¨ï¼š%s", trend_tickers)

    market_sentiment = analyze_market_sentiment(trend_tickers)
    market_status_value = market_sentiment.get("status", MarketSentiment.POSITIVE.value)
    market_status_details_value = market_sentiment.get("details", "")
    logger.info("Layer 1 â€” å¸‚å ´æƒ…ç·’ï¼š%sï¼ˆ%sï¼‰", market_status_value, market_status_details_value)

    # === Layer 2 & 3: é€è‚¡åˆ†æ + Decision Engineï¼ˆä¸¦è¡Œï¼‰ ===
    all_stocks = repo.find_active_stocks(session)
    stock_map: dict[str, Stock] = {s.ticker: s for s in all_stocks}
    logger.info("æƒæå°è±¡ï¼š%d æª”è‚¡ç¥¨ã€‚", len(all_stocks))

    def _analyze_single_stock(stock: Stock, mkt_status: str) -> dict:
        """å–®ä¸€è‚¡ç¥¨çš„åˆ†æé‚è¼¯ï¼ˆå¯åœ¨ Thread ä¸­åŸ·è¡Œï¼‰ã€‚"""
        ticker = stock.ticker
        alerts: list[str] = []

        if stock.category.value in SKIP_MOAT_CATEGORIES:
            moat_result = {"ticker": ticker, "moat": MoatStatus.NOT_AVAILABLE.value, "details": f"{stock.category.value} ä¸é©ç”¨è­·åŸæ²³åˆ†æ"}
        else:
            moat_result = analyze_moat_trend(ticker)
        moat_value = moat_result.get("moat", MoatStatus.NOT_AVAILABLE.value)
        moat_details = moat_result.get("details", "")

        # Cash é¡ä¸å–å¾—æŠ€è¡“è¨Šè™Ÿ
        if stock.category.value in SKIP_SIGNALS_CATEGORIES:
            signals = None
        else:
            signals = get_technical_signals(ticker)
        rsi: float | None = None
        bias: float | None = None
        volume_ratio: float | None = None
        price: float | None = None

        if signals and "error" not in signals:
            rsi = signals.get("rsi")
            bias = signals.get("bias")
            volume_ratio = signals.get("volume_ratio")
            price = signals.get("price")
        elif signals and "error" in signals:
            alerts.append(signals["error"])

        signal = determine_scan_signal(moat_value, mkt_status, rsi, bias)

        if signal == ScanSignal.THESIS_BROKEN:
            alerts.append(f"ğŸ”´ {ticker} è­·åŸæ²³é¬†å‹•ï¼{moat_details}")
        elif signal == ScanSignal.CONTRARIAN_BUY:
            alerts.append(f"ğŸŸ¢ {ticker} é€†å‹¢è²·å…¥è¨Šè™Ÿï¼ˆRSI={rsi}ï¼Œå¸‚å ´æ­£é¢ï¼‰")
        elif signal == ScanSignal.OVERHEATED:
            alerts.append(f"ğŸŸ  {ticker} ä¹–é›¢ç‡éç†±ï¼ˆBias={bias}%ï¼‰")

        if moat_value == MoatStatus.STABLE.value and moat_details:
            alerts.append(f"ğŸŸ¢ {ticker} {moat_details}")
        if moat_value == MoatStatus.NOT_AVAILABLE.value and moat_details:
            alerts.append(f"âš ï¸ {ticker} {moat_details}")

        logger.info(
            "%s â†’ signal=%s, moat=%s, rsi=%s, bias=%s, vol_ratio=%s",
            ticker, signal.value, moat_value, rsi, bias, volume_ratio,
        )

        return {
            "ticker": ticker,
            "category": stock.category,
            "signal": signal.value,
            "alerts": alerts,
            "moat": moat_value,
            "bias": bias,
            "volume_ratio": volume_ratio,
            "price": price,
            "rsi": rsi,
            "market_status": market_status_value,
        }

    results: list[dict] = []
    with ThreadPoolExecutor(max_workers=SCAN_THREAD_POOL_SIZE) as executor:
        futures = {
            executor.submit(_analyze_single_stock, s, market_status_value): s
            for s in all_stocks
        }
        for future in as_completed(futures):
            try:
                results.append(future.result())
            except Exception as exc:
                stock = futures[future]
                logger.error("æƒæ %s å¤±æ•—ï¼š%s", stock.ticker, exc, exc_info=True)

    # === æŒä¹…åŒ–æƒæç´€éŒ„ ===
    for r in results:
        scan_log = ScanLog(
            stock_ticker=r["ticker"],
            signal=r["signal"],
            market_status=market_status_value,
            market_status_details=market_status_details_value,
            details=json.dumps(r["alerts"], ensure_ascii=False),
        )
        repo.create_scan_log(session, scan_log)
    session.commit()

    # === æª¢æŸ¥è‡ªè¨‚åƒ¹æ ¼è­¦å ± ===
    _check_price_alerts(session, results)

    # === å·®ç•°æ¯”å° + é€šçŸ¥ ===
    category_icon = CATEGORY_ICON

    # æ¯”å°æ¯æª”è‚¡ç¥¨çš„ current signal vs last_scan_signal
    new_or_changed: list[dict] = []  # signal å¾ NORMALâ†’é NORMALï¼Œæˆ–é NORMAL é¡å‹æ”¹è®Š
    resolved: list[dict] = []        # signal å¾é NORMALâ†’NORMAL
    signal_updates: dict[str, str] = {}

    for r in results:
        ticker = r["ticker"]
        current_signal = r["signal"]
        stock_obj = stock_map.get(ticker)
        prev_signal = stock_obj.last_scan_signal if stock_obj else ScanSignal.NORMAL.value

        signal_updates[ticker] = current_signal

        if current_signal == prev_signal:
            continue  # ç„¡è®ŠåŒ–ï¼Œä¸é€šçŸ¥
        if current_signal != ScanSignal.NORMAL.value:
            new_or_changed.append(r)
        else:
            resolved.append(r)

    # æŒä¹…åŒ–æ‰€æœ‰è‚¡ç¥¨çš„æœ€æ–° signalï¼ˆä¸è«–æ˜¯å¦æœ‰è®ŠåŒ–ï¼‰
    repo.bulk_update_scan_signals(session, signal_updates)

    has_changes = bool(new_or_changed) or bool(resolved)

    if has_changes:
        logger.warning(
            "æƒæå·®ç•°ï¼š%d æª”æ–°å¢/è®Šæ›´ï¼Œ%d æª”å·²æ¢å¾©ã€‚",
            len(new_or_changed), len(resolved),
        )
        header = f"ğŸ”” <b>Folio æƒæï¼ˆå·®ç•°é€šçŸ¥ï¼‰</b>\nå¸‚å ´æƒ…ç·’ï¼š{market_status_value}\n"

        # æ–°å¢/æƒ¡åŒ–çš„è‚¡ç¥¨ä¾é¡åˆ¥åˆ†çµ„
        body_parts: list[str] = []
        if new_or_changed:
            grouped: dict[str, list[str]] = {}
            for r in new_or_changed:
                cat = r.get("category", DEFAULT_IMPORT_CATEGORY)
                cat_value = cat.value if hasattr(cat, "value") else str(cat)
                grouped.setdefault(cat_value, []).extend(r["alerts"])

            for cat_key in CATEGORY_DISPLAY_ORDER:
                if cat_key in grouped:
                    icon = category_icon.get(cat_key, "")
                    label = CATEGORY_LABEL.get(cat_key, cat_key)
                    section_header = f"\n{icon} <b>{label}</b>"
                    section_lines = "\n".join(grouped[cat_key])
                    body_parts.append(f"{section_header}\n{section_lines}")

        # æ¢å¾©æ­£å¸¸çš„è‚¡ç¥¨
        if resolved:
            resolved_tickers = ", ".join(r["ticker"] for r in resolved)
            body_parts.append(f"\nâœ… <b>å·²æ¢å¾©æ­£å¸¸</b>\n{resolved_tickers}")

        send_telegram_message_dual(header + "\n".join(body_parts), session)
    else:
        logger.info("æƒæå®Œæˆï¼Œè¨Šè™Ÿç„¡è®ŠåŒ–ï¼Œè·³éé€šçŸ¥ã€‚")

    return {"market_status": market_sentiment, "results": results}


def _check_price_alerts(session: Session, results: list[dict]) -> None:
    """æª¢æŸ¥æ‰€æœ‰å•Ÿç”¨ä¸­çš„è‡ªè¨‚åƒ¹æ ¼è­¦å ±ï¼Œè§¸ç™¼æ™‚ç™¼é€ Telegram é€šçŸ¥ã€‚"""
    all_alerts = repo.find_all_active_alerts(session)
    if not all_alerts:
        return

    # å»ºç«‹ ticker â†’ result å¿«æŸ¥è¡¨
    result_map = {r["ticker"]: r for r in results}
    triggered_msgs: list[str] = []
    now = datetime.now(timezone.utc)

    for alert in all_alerts:
        r = result_map.get(alert.stock_ticker)
        if not r:
            continue

        # å–å¾—æŒ‡æ¨™å€¼
        metric_value: float | None = None
        if alert.metric == "rsi":
            metric_value = r.get("rsi")
        elif alert.metric == "price":
            metric_value = r.get("price")
        elif alert.metric == "bias":
            metric_value = r.get("bias")

        if metric_value is None:
            continue

        # æ¯”è¼ƒ
        triggered = False
        if alert.operator == "lt" and metric_value < alert.threshold:
            triggered = True
        elif alert.operator == "gt" and metric_value > alert.threshold:
            triggered = True

        if not triggered:
            continue

        # å†·å»æª¢æŸ¥
        if alert.last_triggered_at:
            cooldown = timedelta(hours=PRICE_ALERT_COOLDOWN_HOURS)
            if now - alert.last_triggered_at < cooldown:
                continue

        # è§¸ç™¼
        alert.last_triggered_at = now
        session.add(alert)
        op_label = "<" if alert.operator == "lt" else ">"
        triggered_msgs.append(
            f"ğŸ”” {alert.stock_ticker} {alert.metric}={metric_value} "
            f"{op_label} {alert.threshold}"
        )

    if triggered_msgs:
        session.commit()
        msg = "âš¡ <b>è‡ªè¨‚åƒ¹æ ¼è­¦å ±è§¸ç™¼</b>\n\n" + "\n".join(triggered_msgs)
        send_telegram_message_dual(msg, session)
        logger.warning("è§¸ç™¼ %d å€‹è‡ªè¨‚åƒ¹æ ¼è­¦å ±ã€‚", len(triggered_msgs))


# ===========================================================================
# Scan History Service
# ===========================================================================


def get_scan_history(session: Session, ticker: str, limit: int = SCAN_HISTORY_DEFAULT_LIMIT) -> list[dict]:
    """å–å¾—æŒ‡å®šè‚¡ç¥¨çš„æƒææ­·å²ã€‚"""
    stock = _get_stock_or_raise(session, ticker)
    logs = repo.find_scan_history(session, stock.ticker, limit)
    return [
        {
            "signal": log.signal,
            "market_status": log.market_status,
            "details": log.details,
            "scanned_at": log.scanned_at.isoformat() if log.scanned_at else None,
        }
        for log in logs
    ]


def get_latest_scan_logs(session: Session, limit: int = LATEST_SCAN_LOGS_DEFAULT_LIMIT) -> list[dict]:
    """å–å¾—æœ€è¿‘çš„æƒæç´€éŒ„ã€‚"""
    logs = repo.find_latest_scan_logs(session, limit)
    return [
        {
            "ticker": log.stock_ticker,
            "signal": log.signal,
            "market_status": log.market_status,
            "details": log.details,
            "scanned_at": log.scanned_at.isoformat() if log.scanned_at else None,
        }
        for log in logs
    ]


# ===========================================================================
# Price Alert Service
# ===========================================================================


def create_price_alert(
    session: Session,
    ticker: str,
    metric: str,
    operator: str,
    threshold: float,
) -> dict:
    """å»ºç«‹è‡ªè¨‚åƒ¹æ ¼è­¦å ±ã€‚"""
    stock = _get_stock_or_raise(session, ticker)
    ticker_upper = stock.ticker

    alert = PriceAlert(
        stock_ticker=ticker_upper,
        metric=metric,
        operator=operator,
        threshold=threshold,
    )
    saved = repo.create_price_alert(session, alert)
    op_label = "<" if operator == "lt" else ">"
    return {
        "message": f"âœ… å·²å»ºç«‹è­¦å ±ï¼š{ticker_upper} {metric} {op_label} {threshold}",
        "id": saved.id,
    }


def list_price_alerts(session: Session, ticker: str) -> list[dict]:
    """å–å¾—æŒ‡å®šè‚¡ç¥¨çš„æ‰€æœ‰è­¦å ±ã€‚"""
    alerts = repo.find_all_alerts_for_stock(session, ticker.upper())
    return [
        {
            "id": a.id,
            "metric": a.metric,
            "operator": a.operator,
            "threshold": a.threshold,
            "is_active": a.is_active,
            "last_triggered_at": (
                a.last_triggered_at.isoformat() if a.last_triggered_at else None
            ),
        }
        for a in alerts
    ]


def delete_price_alert(session: Session, alert_id: int) -> dict:
    """åˆªé™¤åƒ¹æ ¼è­¦å ±ã€‚"""
    alert = repo.find_price_alert_by_id(session, alert_id)
    if not alert:
        return {"message": "âš ï¸ æ‰¾ä¸åˆ°æ­¤è­¦å ±ã€‚"}
    repo.delete_price_alert(session, alert)
    return {"message": "âœ… è­¦å ±å·²åˆªé™¤ã€‚"}


# ===========================================================================
# Weekly Digest Service
# ===========================================================================


def send_weekly_digest(session: Session) -> dict:
    """
    ç™¼é€æ¯é€± Telegram æ‘˜è¦ï¼š
    - ç›®å‰æ‰€æœ‰é NORMAL è‚¡ç¥¨
    - éå» 7 å¤©è¨Šè™Ÿè®ŠåŒ–
    - æŠ•è³‡çµ„åˆå¥åº·åˆ†æ•¸
    """
    logger.info("é–‹å§‹ç”Ÿæˆæ¯é€±æ‘˜è¦...")

    all_stocks = repo.find_active_stocks(session)
    total = len(all_stocks)
    if total == 0:
        send_telegram_message_dual("ğŸ“Š <b>Folio æ¯é€±æ‘˜è¦</b>\n\nç›®å‰ç„¡è¿½è¹¤è‚¡ç¥¨ã€‚", session)
        return {"message": "ç„¡è¿½è¹¤è‚¡ç¥¨ã€‚"}

    # ç›®å‰é NORMAL è‚¡ç¥¨
    non_normal = [s for s in all_stocks if s.last_scan_signal != ScanSignal.NORMAL.value]
    normal_count = total - len(non_normal)
    health_score = round(normal_count / total * 100, 1)

    # éå» 7 å¤©çš„è¨Šè™Ÿè®ŠåŒ–
    seven_days_ago = datetime.now(timezone.utc) - timedelta(days=WEEKLY_DIGEST_LOOKBACK_DAYS)
    recent_logs = repo.find_scan_logs_since(session, seven_days_ago)

    # çµ±è¨ˆæ¯æª”è‚¡ç¥¨çš„è¨Šè™Ÿè®ŠåŒ–æ¬¡æ•¸
    signal_changes: dict[str, int] = {}
    prev_signals: dict[str, str] = {}
    # æŒ‰æ™‚é–“æ­£åºè™•ç†ï¼ˆæœ€èˆŠâ†’æœ€æ–°ï¼‰
    for log in reversed(recent_logs):
        tk = log.stock_ticker
        if tk in prev_signals and prev_signals[tk] != log.signal:
            signal_changes[tk] = signal_changes.get(tk, 0) + 1
        prev_signals[tk] = log.signal

    # çµ„åˆè¨Šæ¯
    parts: list[str] = [
        f"ğŸ“Š <b>Folio æ¯é€±æ‘˜è¦</b>\n",
        f"ğŸ¥ æŠ•è³‡çµ„åˆå¥åº·åˆ†æ•¸ï¼š<b>{health_score}%</b>ï¼ˆ{normal_count}/{total} æ­£å¸¸ï¼‰\n",
    ]

    if non_normal:
        parts.append("âš ï¸ <b>ç›®å‰ç•°å¸¸è‚¡ç¥¨ï¼š</b>")
        for s in non_normal:
            cat_label = CATEGORY_LABEL.get(s.category.value, s.category.value)
            parts.append(f"  â€¢ {s.ticker}ï¼ˆ{cat_label}ï¼‰â†’ {s.last_scan_signal}")

    if signal_changes:
        parts.append("\nğŸ”„ <b>æœ¬é€±è¨Šè™Ÿè®ŠåŒ–ï¼š</b>")
        for tk, count in sorted(signal_changes.items(), key=lambda x: -x[1]):
            parts.append(f"  â€¢ {tk}ï¼šè®ŠåŒ– {count} æ¬¡")

    if not non_normal and not signal_changes:
        parts.append("âœ… ä¸€åˆ‡æ­£å¸¸ï¼Œæœ¬é€±ç„¡ç•°å¸¸è¨Šè™Ÿã€‚")

    message = "\n".join(parts)
    send_telegram_message_dual(message, session)
    logger.info("æ¯é€±æ‘˜è¦å·²ç™¼é€ã€‚")

    return {"message": "æ¯é€±æ‘˜è¦å·²ç™¼é€ã€‚", "health_score": health_score}


# ===========================================================================
# Portfolio Summary Service (for OpenClaw / chat)
# ===========================================================================


def get_portfolio_summary(session: Session) -> str:
    """
    ç”¢ç”Ÿç´”æ–‡å­—æŠ•è³‡çµ„åˆæ‘˜è¦ï¼Œå°ˆç‚º chat / AI agent è¨­è¨ˆã€‚
    """
    stocks = repo.find_active_stocks(session)
    if not stocks:
        return "Folio â€” ç›®å‰ç„¡è¿½è¹¤è‚¡ç¥¨ã€‚"

    non_normal = [s for s in stocks if s.last_scan_signal != ScanSignal.NORMAL.value]
    health = round((len(stocks) - len(non_normal)) / len(stocks) * 100, 1)

    lines: list[str] = [f"Folio â€” Health: {health}%", ""]

    for cat in CATEGORY_DISPLAY_ORDER:
        group = [s for s in stocks if s.category.value == cat]
        if group:
            label = CATEGORY_LABEL.get(cat, cat)
            lines.append(f"[{label}] {', '.join(s.ticker for s in group)}")

    if non_normal:
        lines += ["", "Abnormal:"]
        for s in non_normal:
            lines.append(f"  {s.ticker} -> {s.last_scan_signal}")
    else:
        lines += ["", "All signals normal."]

    return "\n".join(lines)


# ===========================================================================
# Import Service
# ===========================================================================


def import_stocks(session: Session, stock_list: list[dict]) -> dict:
    """
    æ‰¹æ¬¡åŒ¯å…¥è‚¡ç¥¨ï¼ˆupsert é‚è¼¯ï¼‰ã€‚
    æ–°è‚¡ç¥¨å»ºç«‹ï¼Œå·²å­˜åœ¨çš„æ›´æ–°è§€é»èˆ‡æ¨™ç±¤ã€‚
    """
    logger.info("æ‰¹æ¬¡åŒ¯å…¥ %d ç­†è‚¡ç¥¨...", len(stock_list))
    created = 0
    updated = 0
    errors: list[str] = []

    for item in stock_list:
        ticker = item.get("ticker", "").strip().upper()
        category_str = item.get("category", DEFAULT_IMPORT_CATEGORY)
        thesis = item.get("thesis", "") or item.get("initial_thesis", "")
        tags = item.get("tags", [])

        if not ticker:
            errors.append("ç¼ºå°‘ ticker æ¬„ä½")
            continue

        try:
            category = StockCategory(category_str)
        except ValueError:
            errors.append(f"{ticker}: ç„¡æ•ˆåˆ†é¡ {category_str}")
            continue

        existing = repo.find_stock_by_ticker(session, ticker)
        tags_str = _tags_to_str(tags)

        if existing:
            # Upsert: æ›´æ–°è§€é»èˆ‡æ¨™ç±¤
            if thesis:
                _append_thesis_log(session, ticker, thesis, tags_str)
                existing.current_thesis = thesis
            if tags:
                existing.current_tags = tags_str
            existing.category = category
            repo.update_stock(session, existing)
            updated += 1
        else:
            # æ–°å¢
            stock = Stock(
                ticker=ticker,
                category=category,
                current_thesis=thesis,
                current_tags=tags_str,
                is_active=True,
            )
            session.add(stock)
            thesis_log = ThesisLog(
                stock_ticker=ticker,
                content=thesis,
                tags=tags_str,
                version=1,
            )
            repo.create_thesis_log(session, thesis_log)
            created += 1

    session.commit()
    logger.info("åŒ¯å…¥å®Œæˆï¼šæ–°å¢ %dï¼Œæ›´æ–° %dï¼ŒéŒ¯èª¤ %dã€‚", created, updated, len(errors))

    return {
        "message": f"âœ… åŒ¯å…¥å®Œæˆï¼šæ–°å¢ {created}ï¼Œæ›´æ–° {updated}ï¼ŒéŒ¯èª¤ {len(errors)}ã€‚",
        "created": created,
        "updated": updated,
        "errors": errors,
    }


# ===========================================================================
# Moat Serviceï¼ˆBond / Cash ä¸é©ç”¨ï¼‰
# ===========================================================================


def get_moat_for_ticker(session: Session, ticker: str) -> dict:
    """å–å¾—æŒ‡å®šè‚¡ç¥¨çš„è­·åŸæ²³è¶¨å‹¢ã€‚Bond / Cash é¡åˆ¥ç›´æ¥å›å‚³ N/Aã€‚"""
    upper_ticker = ticker.upper()
    stock = repo.find_stock_by_ticker(session, upper_ticker)
    if stock and stock.category.value in SKIP_MOAT_CATEGORIES:
        return {"ticker": upper_ticker, "moat": "N/A", "details": f"{stock.category.value} ä¸é©ç”¨è­·åŸæ²³åˆ†æ"}
    return analyze_moat_trend(upper_ticker)


# ===========================================================================
# Webhook Service (for OpenClaw / AI agents)
# ===========================================================================


def handle_webhook(session: Session, action: str, ticker: str | None, params: dict) -> dict:
    """
    è™•ç† AI agent webhook è«‹æ±‚ã€‚å›å‚³ dict(success, message, data)ã€‚
    æ¥­å‹™é‚è¼¯é›†ä¸­æ–¼æ­¤ï¼ŒAPI handler åªè² è²¬ parse + å›å‚³ã€‚
    """
    import threading as _threading

    action = action.lower().strip()
    ticker = ticker.upper().strip() if ticker else None

    # Validate action against registry
    if action not in WEBHOOK_ACTION_REGISTRY:
        supported = ", ".join(sorted(WEBHOOK_ACTION_REGISTRY.keys()))
        return {"success": False, "message": f"ä¸æ”¯æ´çš„ action: {action}ã€‚æ”¯æ´ï¼š{supported}"}

    if action == "help":
        return {
            "success": True,
            "message": "ä»¥ä¸‹æ˜¯æ‰€æœ‰æ”¯æ´çš„ webhook actionsã€‚",
            "data": {"actions": WEBHOOK_ACTION_REGISTRY},
        }

    if action == "summary":
        text = get_portfolio_summary(session)
        return {"success": True, "message": text}

    if action == "signals":
        if not ticker:
            return {"success": False, "message": WEBHOOK_MISSING_TICKER}
        result = get_technical_signals(ticker)
        if not result or "error" in result:
            return {
                "success": False,
                "message": result.get("error", "ç„¡æ³•å–å¾—æŠ€è¡“è¨Šè™Ÿã€‚") if result else "ç„¡æ³•å–å¾—æŠ€è¡“è¨Šè™Ÿã€‚",
            }
        status_text = "\n".join(result.get("status", []))
        msg = (
            f"{ticker} â€” ç¾åƒ¹ ${result.get('price')}, RSI={result.get('rsi')}, "
            f"Bias={result.get('bias')}%\n{status_text}"
        )
        return {"success": True, "message": msg, "data": result}

    if action == "scan":
        from infrastructure.database import engine as _engine

        def _bg_scan() -> None:
            with Session(_engine) as s:
                run_scan(s)

        _threading.Thread(target=_bg_scan, daemon=True).start()
        return {"success": True, "message": "æƒæå·²åœ¨èƒŒæ™¯å•Ÿå‹•ï¼Œçµæœå°‡é€é Telegram é€šçŸ¥ã€‚"}

    if action == "moat":
        if not ticker:
            return {"success": False, "message": WEBHOOK_MISSING_TICKER}
        result = analyze_moat_trend(ticker)
        details = result.get("details", "N/A")
        return {
            "success": True,
            "message": f"{ticker} è­·åŸæ²³ï¼š{result.get('moat', 'N/A')} â€” {details}",
            "data": result,
        }

    if action == "alerts":
        if not ticker:
            return {"success": False, "message": WEBHOOK_MISSING_TICKER}
        alerts = list_price_alerts(session, ticker)
        if not alerts:
            return {"success": True, "message": f"{ticker} ç›®å‰æ²’æœ‰è¨­å®šåƒ¹æ ¼è­¦å ±ã€‚"}
        lines = [f"{ticker} åƒ¹æ ¼è­¦å ±ï¼š"]
        for a in alerts:
            op_str = "<" if a["operator"] == "lt" else ">"
            lines.append(f"  {a['metric']} {op_str} {a['threshold']} ({'å•Ÿç”¨' if a['is_active'] else 'åœç”¨'})")
        return {"success": True, "message": "\n".join(lines), "data": {"alerts": alerts}}

    if action == "add_stock":
        t = params.get("ticker", ticker)
        if not t:
            return {"success": False, "message": WEBHOOK_MISSING_TICKER}
        cat_str = params.get("category", DEFAULT_IMPORT_CATEGORY)
        thesis = params.get("thesis", DEFAULT_WEBHOOK_THESIS)
        tags = params.get("tags", [])
        try:
            stock = create_stock(session, t, StockCategory(cat_str), thesis, tags)
            return {"success": True, "message": f"âœ… å·²æ–°å¢ {stock.ticker} åˆ° {cat_str} åˆ†é¡ã€‚"}
        except StockAlreadyExistsError as e:
            return {"success": False, "message": str(e)}
        except ValueError:
            return {"success": False, "message": f"ç„¡æ•ˆçš„åˆ†é¡ï¼š{cat_str}"}

    # Fallback â€” should not reach here if registry is in sync
    supported = ", ".join(sorted(WEBHOOK_ACTION_REGISTRY.keys()))
    return {"success": False, "message": f"ä¸æ”¯æ´çš„ action: {action}ã€‚æ”¯æ´ï¼š{supported}"}


# ===========================================================================
# Asset Allocation â€” å†å¹³è¡¡åˆ†æ
# ===========================================================================


def calculate_rebalance(session: Session, display_currency: str = "USD") -> dict:
    """
    è¨ˆç®—å†å¹³è¡¡åˆ†æï¼šæ¯”è¼ƒç›®æ¨™é…ç½®èˆ‡å¯¦éš›æŒå€‰ã€‚
    1. è®€å–å•Ÿç”¨ä¸­çš„ UserInvestmentProfileï¼ˆç›®æ¨™é…ç½®ï¼‰
    2. è®€å–æ‰€æœ‰ Holdingï¼ˆå¯¦éš›æŒå€‰ï¼‰
    3. å–å¾—åŒ¯ç‡ï¼Œå°‡æ‰€æœ‰æŒå€‰è½‰æ›ç‚º display_currency
    4. å°éç¾é‡‘æŒå€‰æŸ¥è©¢å³æ™‚åƒ¹æ ¼
    5. å§”è¨— domain.rebalance ç´”å‡½å¼è¨ˆç®—åç§»èˆ‡å»ºè­°
    """
    import json as _json

    from domain.entities import Holding, UserInvestmentProfile
    from domain.rebalance import calculate_rebalance as _pure_rebalance
    from infrastructure.market_data import get_technical_signals

    # 1) å–å¾—ç›®æ¨™é…ç½®
    profile = session.exec(
        select(UserInvestmentProfile)
        .where(UserInvestmentProfile.user_id == DEFAULT_USER_ID)
        .where(UserInvestmentProfile.is_active == True)  # noqa: E712
    ).first()

    if not profile:
        raise StockNotFoundError("å°šæœªè¨­å®šæŠ•è³‡çµ„åˆç›®æ¨™é…ç½®ï¼Œè«‹å…ˆé¸æ“‡æŠ•è³‡äººæ ¼ã€‚")

    target_config: dict[str, float] = _json.loads(profile.config)

    # 2) å–å¾—æ‰€æœ‰æŒå€‰
    holdings = session.exec(
        select(Holding).where(Holding.user_id == DEFAULT_USER_ID)
    ).all()

    if not holdings:
        raise StockNotFoundError("å°šæœªè¼¸å…¥ä»»ä½•æŒå€‰ï¼Œè«‹å…ˆæ–°å¢è³‡ç”¢ã€‚")

    # 3) å–å¾—åŒ¯ç‡ï¼šæ”¶é›†æ‰€æœ‰æŒå€‰å¹£åˆ¥ï¼Œæ‰¹æ¬¡å–å¾—ç›¸å° display_currency çš„åŒ¯ç‡
    holding_currencies = list({h.currency for h in holdings})
    fx_rates = get_exchange_rates(display_currency, holding_currencies)
    logger.info(
        "åŒ¯ç‡è½‰æ›ï¼ˆâ†’ %sï¼‰ï¼š%s",
        display_currency,
        {k: round(v, 4) for k, v in fx_rates.items()},
    )

    # 4) è¨ˆç®—å„æŒå€‰çš„å¸‚å€¼ï¼ˆå·²æ›ç®—ç‚º display_currencyï¼‰ï¼ŒåŒæ™‚å»ºç«‹å€‹è‚¡æ˜ç´°
    category_values: dict[str, float] = {}
    ticker_agg: dict[str, dict] = {}

    for h in holdings:
        cat = h.category.value if hasattr(h.category, "value") else str(h.category)
        fx = fx_rates.get(h.currency, 1.0)
        price: float | None = None

        if h.is_cash:
            # ç¾é‡‘æŒå€‰ï¼šquantity å³é¢é¡ï¼Œéœ€ä»¥åŒ¯ç‡æ›ç®—
            market_value = h.quantity * fx
            price = 1.0
        else:
            signals = get_technical_signals(h.ticker)
            price = signals.get("price") if signals else None
            if price is not None and isinstance(price, (int, float)):
                market_value = h.quantity * price * fx
            elif h.cost_basis is not None:
                market_value = h.quantity * h.cost_basis * fx
            else:
                market_value = 0.0

        category_values[cat] = category_values.get(cat, 0.0) + market_value

        # Aggregate by ticker (merge across brokers)
        key = h.ticker
        if key not in ticker_agg:
            ticker_agg[key] = {
                "category": cat,
                "currency": h.currency,
                "qty": 0.0,
                "mv": 0.0,
                "cost_sum": 0.0,
                "cost_qty": 0.0,
                "price": price,
                "fx": fx,
            }
        ticker_agg[key]["qty"] += h.quantity
        ticker_agg[key]["mv"] += market_value
        if h.cost_basis is not None:
            ticker_agg[key]["cost_sum"] += h.cost_basis * h.quantity
            ticker_agg[key]["cost_qty"] += h.quantity

    # 5) å§”è¨— domain ç´”å‡½å¼è¨ˆç®—
    result = _pure_rebalance(category_values, target_config)

    # 6) å»ºç«‹å€‹è‚¡æ˜ç´°ï¼ˆå«ä½”æ¯”ï¼‰
    total_value = result["total_value"]
    holdings_detail = []
    for ticker, agg in ticker_agg.items():
        avg_cost = (
            round(agg["cost_sum"] / agg["cost_qty"], 2)
            if agg["cost_qty"] > 0
            else None
        )
        weight_pct = (
            round((agg["mv"] / total_value) * 100, 2) if total_value > 0 else 0.0
        )
        cur_price = agg["price"]
        holdings_detail.append(
            {
                "ticker": ticker,
                "category": agg["category"],
                "currency": agg["currency"],
                "quantity": round(agg["qty"], 4),
                "market_value": round(agg["mv"], 2),
                "weight_pct": weight_pct,
                "avg_cost": avg_cost,
                "current_price": (
                    round(cur_price, 2)
                    if cur_price is not None and isinstance(cur_price, (int, float))
                    else None
                ),
            }
        )

    # Sort by weight descending (largest positions first)
    holdings_detail.sort(key=lambda x: x["weight_pct"], reverse=True)
    result["holdings_detail"] = holdings_detail
    result["display_currency"] = display_currency

    # 7) X-Ray: ç©¿é€å¼æŒå€‰åˆ†æï¼ˆè§£æ ETF æˆåˆ†è‚¡ï¼Œè¨ˆç®—çœŸå¯¦æ›éšªï¼‰
    xray_map: dict[str, dict] = {}  # symbol -> {direct, indirect, sources, name}

    for ticker, agg in ticker_agg.items():
        cat = agg["category"]
        mv = agg["mv"]
        if cat in XRAY_SKIP_CATEGORIES or mv <= 0:
            continue

        # å˜—è©¦å–å¾— ETF æˆåˆ†è‚¡
        constituents = get_etf_top_holdings(ticker)
        if constituents:
            # æ­¤ ticker æ˜¯ ETF â€” è¨ˆç®—é–“æ¥æ›éšª
            for c in constituents:
                sym = c["symbol"]
                weight = c["weight"]
                indirect_mv = mv * weight
                if sym not in xray_map:
                    xray_map[sym] = {
                        "name": c.get("name", ""),
                        "direct": 0.0,
                        "indirect": 0.0,
                        "sources": [],
                    }
                xray_map[sym]["indirect"] += indirect_mv
                src_pct = round(weight * 100, 2)
                xray_map[sym]["sources"].append(f"{ticker} ({src_pct}%)")
        else:
            # é ETF â€” è¨˜éŒ„ç‚ºç›´æ¥æŒå€‰
            if ticker not in xray_map:
                xray_map[ticker] = {
                    "name": "",
                    "direct": 0.0,
                    "indirect": 0.0,
                    "sources": [],
                }
            xray_map[ticker]["direct"] += mv

    # çµ„åˆ X-Ray çµæœ
    xray_entries = []
    for symbol, data in xray_map.items():
        total_val = data["direct"] + data["indirect"]
        if total_val <= 0:
            continue
        direct_pct = round((data["direct"] / total_value) * 100, 2) if total_value > 0 else 0.0
        indirect_pct = round((data["indirect"] / total_value) * 100, 2) if total_value > 0 else 0.0
        total_pct = round((total_val / total_value) * 100, 2) if total_value > 0 else 0.0
        xray_entries.append(
            {
                "symbol": symbol,
                "name": data["name"],
                "direct_value": round(data["direct"], 2),
                "direct_weight_pct": direct_pct,
                "indirect_value": round(data["indirect"], 2),
                "indirect_weight_pct": indirect_pct,
                "total_value": round(total_val, 2),
                "total_weight_pct": total_pct,
                "indirect_sources": data["sources"],
            }
        )

    xray_entries.sort(key=lambda x: x["total_weight_pct"], reverse=True)
    result["xray"] = xray_entries
    result["calculated_at"] = datetime.now(timezone.utc).isoformat()

    return result


def send_xray_warnings(
    xray_entries: list[dict],
    display_currency: str,
    session: Session,
) -> list[str]:
    """
    æª¢æŸ¥ X-Ray çµæœï¼Œå°è¶…éå–®ä¸€æ¨™çš„é¢¨éšªé–€æª»çš„æŒå€‰ç™¼é€ Telegram è­¦å‘Šã€‚
    å›å‚³å·²ç™¼é€çš„è­¦å‘Šè¨Šæ¯åˆ—è¡¨ã€‚
    """
    warnings: list[str] = []
    for entry in xray_entries:
        total_pct = entry.get("total_weight_pct", 0.0)
        indirect_val = entry.get("indirect_value", 0.0)
        if total_pct > XRAY_SINGLE_STOCK_WARN_PCT and indirect_val > 0:
            symbol = entry["symbol"]
            direct_pct = entry.get("direct_weight_pct", 0.0)
            sources = ", ".join(entry.get("indirect_sources", []))
            msg = (
                f"âš ï¸ X-Ray è­¦å‘Šï¼š{symbol} ç›´æ¥æŒå€‰ä½” {direct_pct:.1f}%ï¼Œ"
                f"åŠ ä¸Š ETF é–“æ¥æ›éšªï¼ˆ{sources}ï¼‰ï¼Œ"
                f"çœŸå¯¦æ›éšªå·²é” {total_pct:.1f}%ï¼Œ"
                f"è¶…éå–®ä¸€æ¨™çš„é¢¨éšªå»ºè­°å€¼ {XRAY_SINGLE_STOCK_WARN_PCT:.0f}%ã€‚"
            )
            warnings.append(msg)

    if warnings:
        full_msg = "ğŸ”¬ ç©¿é€å¼æŒå€‰ X-Ray åˆ†æ\n\n" + "\n\n".join(warnings)
        try:
            send_telegram_message_dual(full_msg, session)
            logger.info("å·²ç™¼é€ X-Ray è­¦å‘Šï¼ˆ%d ç­†ï¼‰", len(warnings))
        except Exception as e:
            logger.warning("X-Ray Telegram è­¦å‘Šç™¼é€å¤±æ•—ï¼š%s", e)

    return warnings


# ===========================================================================
# Currency Exposure Monitor
# ===========================================================================


def calculate_currency_exposure(session: Session, home_currency: str | None = None) -> dict:
    """
    è¨ˆç®—åŒ¯ç‡æ›éšªåˆ†æï¼š
    1. è®€å–ä½¿ç”¨è€… Profile çš„ home_currencyï¼ˆæˆ–ä½¿ç”¨åƒæ•¸è¦†å¯«ï¼‰
    2. å°‡æ‰€æœ‰æŒå€‰æŒ‰å¹£åˆ¥åˆ†çµ„ï¼Œè¨ˆç®—ä»¥æœ¬å¹£è¨ˆåƒ¹çš„å¸‚å€¼
    3. åµæ¸¬è¿‘æœŸåŒ¯ç‡è®Šå‹•
    4. ç”¢å‡ºé¢¨éšªç­‰ç´šèˆ‡å»ºè­°
    """
    from domain.entities import Holding, UserInvestmentProfile

    # 1) æ±ºå®šæœ¬å¹£
    if not home_currency:
        profile = session.exec(
            select(UserInvestmentProfile)
            .where(UserInvestmentProfile.user_id == DEFAULT_USER_ID)
            .where(UserInvestmentProfile.is_active == True)  # noqa: E712
        ).first()
        home_currency = profile.home_currency if profile else "TWD"

    # 2) å–å¾—æ‰€æœ‰æŒå€‰
    holdings = session.exec(
        select(Holding).where(Holding.user_id == DEFAULT_USER_ID)
    ).all()

    if not holdings:
        return {
            "home_currency": home_currency,
            "total_value_home": 0.0,
            "breakdown": [],
            "non_home_pct": 0.0,
            "cash_breakdown": [],
            "cash_non_home_pct": 0.0,
            "total_cash_home": 0.0,
            "fx_movements": [],
            "risk_level": "low",
            "advice": ["å°šç„¡æŒå€‰è³‡æ–™ã€‚"],
            "calculated_at": datetime.now(timezone.utc).isoformat(),
        }

    # 3) å–å¾—åŒ¯ç‡ï¼ˆall currencies â†’ home_currencyï¼‰
    holding_currencies = list({h.currency for h in holdings})
    fx_rates = get_exchange_rates(home_currency, holding_currencies)
    logger.info("åŒ¯ç‡æ›éšªåˆ†æ â†’ %sï¼š%s", home_currency, {k: round(v, 4) for k, v in fx_rates.items()})

    # 4) æŒ‰å¹£åˆ¥åˆ†çµ„è¨ˆç®—å¸‚å€¼ï¼ˆä»¥æœ¬å¹£è¨ˆåƒ¹ï¼‰â€” åŒæ™‚è¿½è¹¤ç¾é‡‘éƒ¨ä½
    currency_values: dict[str, float] = {}
    cash_currency_values: dict[str, float] = {}
    for h in holdings:
        fx = fx_rates.get(h.currency, 1.0)
        if h.is_cash:
            market_value = h.quantity * fx
            cash_currency_values[h.currency] = (
                cash_currency_values.get(h.currency, 0.0) + market_value
            )
        else:
            signals = get_technical_signals(h.ticker)
            price = signals.get("price") if signals else None
            if price is None:
                # ç„¡æ³•å–å¾—åƒ¹æ ¼ï¼Œä½¿ç”¨æˆæœ¬ä¼°ç®—
                price = h.cost_basis or 0.0
            market_value = h.quantity * price * fx

        currency_values[h.currency] = currency_values.get(h.currency, 0.0) + market_value

    total_value_home = sum(currency_values.values())
    total_cash_home = sum(cash_currency_values.values())

    # 5) å»ºç«‹å¹£åˆ¥åˆ†ä½ˆï¼ˆå…¨è³‡ç”¢ï¼‰
    breakdown = []
    for cur, val in sorted(currency_values.items(), key=lambda x: x[1], reverse=True):
        pct = round((val / total_value_home) * 100, 2) if total_value_home > 0 else 0.0
        breakdown.append({
            "currency": cur,
            "value": round(val, 2),
            "percentage": pct,
            "is_home": cur == home_currency,
        })

    non_home_pct = round(
        sum(b["percentage"] for b in breakdown if not b["is_home"]),
        2,
    )

    # 5b) å»ºç«‹ç¾é‡‘å¹£åˆ¥åˆ†ä½ˆ
    cash_breakdown = []
    for cur, val in sorted(cash_currency_values.items(), key=lambda x: x[1], reverse=True):
        pct = round((val / total_cash_home) * 100, 2) if total_cash_home > 0 else 0.0
        cash_breakdown.append({
            "currency": cur,
            "value": round(val, 2),
            "percentage": pct,
            "is_home": cur == home_currency,
        })

    cash_non_home_pct = round(
        sum(b["percentage"] for b in cash_breakdown if not b["is_home"]),
        2,
    )

    # 6) åµæ¸¬è¿‘æœŸåŒ¯ç‡è®Šå‹•ï¼ˆéæœ¬å¹£ â†’ æœ¬å¹£ï¼‰
    fx_movements = []
    non_home_currencies = [cur for cur in currency_values if cur != home_currency]
    for cur in non_home_currencies:
        history = get_forex_history(cur, home_currency)
        if len(history) >= 2:
            first_close = history[0]["close"]
            last_close = history[-1]["close"]
            if first_close > 0:
                change_pct = round(((last_close - first_close) / first_close) * 100, 2)
                direction = "up" if change_pct > 0 else ("down" if change_pct < 0 else "flat")
                fx_movements.append({
                    "pair": f"{cur}/{home_currency}",
                    "current_rate": last_close,
                    "change_pct": change_pct,
                    "direction": direction,
                })

    # 7) é¢¨éšªç­‰ç´š
    if non_home_pct >= FX_HIGH_CONCENTRATION_PCT:
        risk_level = "high"
    elif non_home_pct >= FX_MEDIUM_CONCENTRATION_PCT:
        risk_level = "medium"
    else:
        risk_level = "low"

    # 8) å»ºè­°ï¼ˆåŒ…å«ç¾é‡‘éƒ¨ä½è³‡è¨Šï¼‰
    advice = _generate_fx_advice(
        home_currency,
        breakdown,
        non_home_pct,
        risk_level,
        fx_movements,
        cash_breakdown=cash_breakdown,
        cash_non_home_pct=cash_non_home_pct,
        total_cash_home=total_cash_home,
    )

    return {
        "home_currency": home_currency,
        "total_value_home": round(total_value_home, 2),
        "breakdown": breakdown,
        "non_home_pct": non_home_pct,
        "cash_breakdown": cash_breakdown,
        "cash_non_home_pct": cash_non_home_pct,
        "total_cash_home": round(total_cash_home, 2),
        "fx_movements": fx_movements,
        "risk_level": risk_level,
        "advice": advice,
        "calculated_at": datetime.now(timezone.utc).isoformat(),
    }


def _generate_fx_advice(
    home_currency: str,
    breakdown: list[dict],
    non_home_pct: float,
    risk_level: str,
    fx_movements: list[dict],
    *,
    cash_breakdown: list[dict] | None = None,
    cash_non_home_pct: float = 0.0,
    total_cash_home: float = 0.0,
) -> list[str]:
    """æ ¹æ“šåŒ¯ç‡æ›éšªåˆ†æçµæœç”¢å‡ºå»ºè­°æ–‡å­—ã€‚"""
    advice: list[str] = []

    # é›†ä¸­åº¦å»ºè­°
    if risk_level == "high":
        top_foreign = [b for b in breakdown if not b["is_home"]]
        if top_foreign:
            top_cur = top_foreign[0]["currency"]
            top_pct = top_foreign[0]["percentage"]
            advice.append(
                f"âš ï¸ éæœ¬å¹£ï¼ˆ{home_currency}ï¼‰è³‡ç”¢ä½”æ¯”é” {non_home_pct:.1f}%ï¼Œ"
                f"å…¶ä¸­ {top_cur} ä½” {top_pct:.1f}%ï¼ŒåŒ¯ç‡é¢¨éšªè¼ƒé«˜ã€‚"
                f"å»ºè­°è©•ä¼°æ˜¯å¦éœ€è¦èª¿æ•´å¹£åˆ¥é…ç½®ä»¥é™ä½å–®ä¸€è²¨å¹£æ›éšªã€‚"
            )
    elif risk_level == "medium":
        advice.append(
            f"ğŸ“Š éæœ¬å¹£è³‡ç”¢ä½”æ¯” {non_home_pct:.1f}%ï¼Œè™•æ–¼ä¸­ç­‰æ°´æº–ã€‚"
            f"æŒçºŒé—œæ³¨ä¸»è¦å¤–å¹£åŒ¯ç‡èµ°å‹¢ã€‚"
        )
    else:
        advice.append(
            f"âœ… éæœ¬å¹£è³‡ç”¢ä½”æ¯” {non_home_pct:.1f}%ï¼ŒåŒ¯ç‡é¢¨éšªè¼ƒä½ã€‚"
        )

    # ç¾é‡‘éƒ¨ä½å°ˆå±¬å»ºè­°
    if cash_breakdown:
        foreign_cash = [b for b in cash_breakdown if not b["is_home"]]
        if foreign_cash and cash_non_home_pct > 0:
            top_cash_cur = foreign_cash[0]["currency"]
            top_cash_val = foreign_cash[0]["value"]
            advice.append(
                f"ğŸ’µ æ‚¨çš„ç¾é‡‘éƒ¨ä½ä¸­ï¼Œ{cash_non_home_pct:.1f}% ç‚ºéæœ¬å¹£ã€‚"
                f"æœ€å¤§å¤–å¹£ç¾é‡‘ç‚º {top_cash_cur}ï¼ˆç´„ {top_cash_val:,.0f} {home_currency}ï¼‰ï¼Œ"
                f"å—åŒ¯ç‡æ³¢å‹•ç›´æ¥å½±éŸ¿ã€‚"
            )

    # åŒ¯ç‡è®Šå‹•å»ºè­°ï¼ˆå«ç¾é‡‘é‡‘é¡ï¼‰
    cash_by_cur = {b["currency"]: b["value"] for b in (cash_breakdown or [])}
    for mv in fx_movements:
        abs_change = abs(mv["change_pct"])
        if abs_change >= FX_SIGNIFICANT_CHANGE_PCT:
            pair = mv["pair"]
            base_cur = pair.split("/")[0]
            cash_amt = cash_by_cur.get(base_cur, 0.0)
            cash_note = (
                f"ï¼ˆå…¶ä¸­ {base_cur} ç¾é‡‘ç´„ {cash_amt:,.0f} {home_currency} ç›´æ¥å—å½±éŸ¿ï¼‰"
                if cash_amt > 0
                else ""
            )
            if mv["direction"] == "up":
                advice.append(
                    f"ğŸ“ˆ {pair} è¿‘æœŸå‡å€¼ {mv['change_pct']:+.2f}%ï¼Œ"
                    f"æ‚¨æŒæœ‰çš„ {base_cur} è³‡ç”¢ä»¥ {home_currency} è¨ˆåƒ¹æ­£åœ¨å¢å€¼ã€‚"
                    f"{cash_note}"
                )
            else:
                advice.append(
                    f"ğŸ“‰ {pair} è¿‘æœŸè²¶å€¼ {mv['change_pct']:+.2f}%ï¼Œ"
                    f"æ‚¨æŒæœ‰çš„ {base_cur} è³‡ç”¢ä»¥ {home_currency} è¨ˆåƒ¹æ­£åœ¨ç¸®æ°´ï¼Œ"
                    f"å»ºè­°ç•™æ„æ˜¯å¦éœ€è¦é¿éšªã€‚{cash_note}"
                )

    return advice


def check_fx_alerts(session: Session) -> list[str]:
    """
    æª¢æŸ¥åŒ¯ç‡æ›éšªè­¦å ±ï¼šåµæ¸¬é¡¯è‘—åŒ¯ç‡è®Šå‹•ï¼Œç”¢å‡º Telegram é€šçŸ¥æ–‡å­—ã€‚
    å›å‚³è­¦å ±è¨Šæ¯åˆ—è¡¨ï¼ˆå¼·èª¿ç¾é‡‘éƒ¨ä½å½±éŸ¿ï¼‰ã€‚
    """
    exposure = calculate_currency_exposure(session)
    alerts: list[str] = []

    home_cur = exposure["home_currency"]
    cash_by_cur = {
        b["currency"]: b["value"]
        for b in exposure.get("cash_breakdown", [])
    }

    # åŒ¯ç‡è®Šå‹•è­¦å ±ï¼ˆå«ç¾é‡‘é‡‘é¡ï¼‰
    for mv in exposure.get("fx_movements", []):
        abs_change = abs(mv["change_pct"])
        if abs_change >= FX_SIGNIFICANT_CHANGE_PCT:
            pair = mv["pair"]
            base_cur = pair.split("/")[0]
            cash_amt = cash_by_cur.get(base_cur, 0.0)
            cash_note = (
                f"\nğŸ’µ å…¶ä¸­ {base_cur} ç¾é‡‘ç´„ {cash_amt:,.0f} {home_cur} ç›´æ¥å—å½±éŸ¿ã€‚"
                if cash_amt > 0
                else ""
            )
            if mv["direction"] == "up":
                alerts.append(
                    f"ğŸ“ˆ {pair} å‡å€¼ {mv['change_pct']:+.2f}%ï¼ˆç¾åƒ¹ {mv['current_rate']:.4f}ï¼‰ã€‚"
                    f"æ‚¨çš„ {base_cur} è³¼è²·åŠ›ä¸Šå‡ã€‚{cash_note}"
                )
            else:
                alerts.append(
                    f"ğŸ“‰ {pair} è²¶å€¼ {mv['change_pct']:+.2f}%ï¼ˆç¾åƒ¹ {mv['current_rate']:.4f}ï¼‰ã€‚"
                    f"æ‚¨çš„ {base_cur} è³‡ç”¢ä»¥ {home_cur} è¨ˆåƒ¹æ­£åœ¨ç¸®æ°´ã€‚{cash_note}"
                )

    # é«˜é›†ä¸­åº¦è­¦å ±ï¼ˆæ•´é«” + ç¾é‡‘ï¼‰
    non_home_pct = exposure.get("non_home_pct", 0.0)
    cash_non_home_pct = exposure.get("cash_non_home_pct", 0.0)
    if non_home_pct >= FX_HIGH_CONCENTRATION_PCT:
        alerts.append(
            f"âš ï¸ éæœ¬å¹£è³‡ç”¢ä½”æ¯”é«˜é” {non_home_pct:.1f}%ï¼ŒåŒ¯ç‡é¢¨éšªé¡¯è‘—ã€‚"
            f"å»ºè­°è©•ä¼°æ˜¯å¦éœ€è¦é™ä½å¤–å¹£æ›éšªã€‚"
        )
    if cash_non_home_pct >= FX_HIGH_CONCENTRATION_PCT:
        total_cash = exposure.get("total_cash_home", 0.0)
        alerts.append(
            f"ğŸ’µ ç¾é‡‘éƒ¨ä½ä¸­éæœ¬å¹£ä½” {cash_non_home_pct:.1f}%"
            f"ï¼ˆç¾é‡‘ç¸½é¡ç´„ {total_cash:,.0f} {home_cur}ï¼‰ï¼Œ"
            f"åŒ¯ç‡é¢¨éšªç›´æ¥å½±éŸ¿æ‚¨çš„æµå‹•æ€§è³‡ç”¢ã€‚"
        )

    return alerts


def send_fx_alerts(session: Session) -> list[str]:
    """
    åŸ·è¡ŒåŒ¯ç‡æ›éšªæª¢æŸ¥ï¼Œè‹¥æœ‰è­¦å ±å‰‡ç™¼é€ Telegram é€šçŸ¥ã€‚
    å›å‚³å·²ç™¼é€çš„è­¦å ±åˆ—è¡¨ã€‚
    """
    alerts = check_fx_alerts(session)

    if alerts:
        full_msg = "ğŸ’± åŒ¯ç‡æ›éšªç›£æ§\n\n" + "\n\n".join(alerts)
        try:
            send_telegram_message_dual(full_msg, session)
            logger.info("å·²ç™¼é€åŒ¯ç‡æ›éšªè­¦å ±ï¼ˆ%d ç­†ï¼‰", len(alerts))
        except Exception as e:
            logger.warning("åŒ¯ç‡æ›éšª Telegram è­¦å ±ç™¼é€å¤±æ•—ï¼š%s", e)

    return alerts
